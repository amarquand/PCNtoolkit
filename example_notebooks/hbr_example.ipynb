{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HBR transfer example\n",
    "\n",
    "Welcome to this example/tutorial notebook that will go through the fitting, evaluation, transfering, and extending of HBR models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pcntoolkit.dataio.norm_data import NormData\n",
    "from pcntoolkit.normative_model.norm_conf import NormConf\n",
    "from pcntoolkit.normative_model.norm_hbr import NormHBR\n",
    "from pcntoolkit.normative_model.norm_factory import create_normative_model\n",
    "from pcntoolkit.regression_model.hbr.hbr_conf import HBRConf\n",
    "from pcntoolkit.regression_model.hbr.prior import make_prior\n",
    "from pcntoolkit.regression_model.hbr.hbr import HBR\n",
    "from pcntoolkit.util.plotter import plot_centiles, plot_qq\n",
    "import arviz as az\n",
    "\n",
    "import pymc.math as math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download a small example dataset from github. Saving this dataset on your local device (under 'resources/data/fcon1000.csv' for example) saves time and bandwidth if you re-run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# If you are running this notebook for the first time, you need to download the dataset from github.\n",
    "# If you have already downloaded the dataset, you can comment out the following line\n",
    "pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/predictive-clinical-neuroscience/PCNtoolkit-demo/refs/heads/main/data/fcon1000.csv\"\n",
    ").to_csv(\"resources/data/fcon1000.csv\", index=False)\n",
    "data = pd.read_csv(\"resources/data/fcon1000.csv\")\n",
    "covariates = [\"age\"]\n",
    "batch_effects = [\"sex\", \"site\"]\n",
    "response_vars = [\"rh_MeanThickness_thickness\", \"WM-hypointensities\"]\n",
    "norm_data = NormData.from_dataframe(\n",
    "    name=\"full\",\n",
    "    dataframe=data,\n",
    "    covariates=[\"age\"],\n",
    "    batch_effects=[\"sex\", \"site\"],\n",
    "    response_vars=[\"rh_MeanThickness_thickness\", \"WM-hypointensities\"],\n",
    ")\n",
    "\n",
    "# Leave two sites out for doing transfer and extend later\n",
    "transfer_sites = [\"Milwaukee_b\", \"Oulu\"]\n",
    "transfer_data, fit_data = norm_data.split_batch_effects(\n",
    "    {\"site\": transfer_sites}, names=(\"transfer\", \"fit\")\n",
    ")\n",
    "\n",
    "# Split into train and test sets\n",
    "train, test = fit_data.train_test_split()\n",
    "transfer_train, transfer_test = transfer_data.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the normative model\n",
    "\n",
    "The normative model will be configured using a `NormConf` object, containing save and log paths and the preprocessing configurations, and a `RegConf` object, specific to the regression model type. \n",
    "\n",
    "Our `NormConf` object configures:\n",
    "- a save path paths and whether to save the model and results\n",
    "- a standardization step for both the covariates (inscaler) and the response vars (outscaler)\n",
    "- a Bspline basis expansion of order 3 with 5 knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration of normative model is valid.\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"resources/hbr/save_dir\"\n",
    "# Create a NormConf object\n",
    "norm_conf = NormConf(\n",
    "    savemodel=True,\n",
    "    saveresults=True,\n",
    "    save_dir=save_dir,\n",
    "    inscaler=\"standardize\",\n",
    "    outscaler=\"standardize\",\n",
    "    basis_function=\"linear\",\n",
    "    basis_function_kwargs={\"order\": 3, \"nknots\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the regression model\n",
    "\n",
    "HBR models need to specificy (possibly recursive) parameter configurations. Here, we configure a HBR model with a Normal likelihood, a bspline regression in `mu` and `sigma`, and a random effect in the intercept of `mu`. Note that because sigma has to be strictly positive, we specify a `softplus` mapping, so that the output of the linear regression is mapped to the positive domain. We also use the mapping_params to scale the mapping by a factor of 3, to avoid spikes in the resulting density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "mu = make_prior(\n",
    "    name=\"mu\",\n",
    "    linear=True,\n",
    "    # slope=make_param(dist_name=\"Normal\", dist_params=(0.0, 5.0)),\n",
    "    slope=make_prior(random=False),\n",
    "    intercept=make_prior(\n",
    "        random=True,\n",
    "        sigma=make_prior(dist_name=\"HalfNormal\", dist_params=(1.0,)),\n",
    "        mu=make_prior(dist_name=\"Normal\", dist_params=(0.0, 0.5)),\n",
    "    ),\n",
    ")\n",
    "sigma = make_prior(\n",
    "    name=\"sigma\",\n",
    "    linear=False,\n",
    "    slope=make_prior(dist_name=\"Normal\", dist_params=(0.0, 3.0)),\n",
    "    intercept=make_prior(\n",
    "        dist_name=\"Normal\",\n",
    "        dist_params=(\n",
    "            1.0,\n",
    "            1.0,\n",
    "        ),\n",
    "    ),\n",
    "    mapping=\"softplus\",\n",
    "    mapping_params=(0.0, 3.0),\n",
    ")\n",
    "\n",
    "epsilon = make_prior(\n",
    "    name=\"epsilon\",\n",
    "    dist_name=\"Normal\",\n",
    "    dist_params=(0.0, 1.0),\n",
    ")\n",
    "\n",
    "delta = make_prior(\n",
    "    name=\"delta\",\n",
    "    dist_name=\"Normal\",\n",
    "    dist_params=(1.0, 1.0),\n",
    "    mapping=\"softplus\",\n",
    "    mapping_params=(0.0, 2.0, 0.3),\n",
    ")\n",
    "\n",
    "\n",
    "# Configure the HBRConf object\n",
    "hbr_conf = HBRConf(\n",
    "    draws=2048,\n",
    "    tune=512,\n",
    "    chains=4,\n",
    "    pymc_cores=16,\n",
    "    likelihood=\"SHASHb\",\n",
    "    mu=mu,\n",
    "    sigma=sigma,\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    nuts_sampler=\"nutpie\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine normative and hbr conf in normative model\n",
    "We can either use the NormHBR constructor, or the factory method to create a normative HBR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.normative_model.norm_hbr.NormHBR at 0x33e692660>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the constructor\n",
    "norm_hbr = NormHBR(norm_conf=norm_conf, reg_conf=hbr_conf)\n",
    "display(norm_hbr)\n",
    "del norm_hbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.normative_model.norm_hbr.NormHBR at 0x33e691fa0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the factory method\n",
    "norm_hbr = create_normative_model(norm_conf, hbr_conf)\n",
    "norm_hbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to fit and predict 2 models\n",
      "Fitting and predicting model for rh_MeanThickness_thickness\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    :root {\n",
       "        --column-width-1: 40%; /* Progress column width */\n",
       "        --column-width-2: 15%; /* Chain column width */\n",
       "        --column-width-3: 15%; /* Divergences column width */\n",
       "        --column-width-4: 15%; /* Step Size column width */\n",
       "        --column-width-5: 15%; /* Gradients/Draw column width */\n",
       "    }\n",
       "\n",
       "    .nutpie {\n",
       "        max-width: 800px;\n",
       "        margin: 10px auto;\n",
       "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "        //color: #333;\n",
       "        //background-color: #fff;\n",
       "        padding: 10px;\n",
       "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
       "        border-radius: 8px;\n",
       "        font-size: 14px; /* Smaller font size for a more compact look */\n",
       "    }\n",
       "    .nutpie table {\n",
       "        width: 100%;\n",
       "        border-collapse: collapse; /* Remove any extra space between borders */\n",
       "    }\n",
       "    .nutpie th, .nutpie td {\n",
       "        padding: 8px 10px; /* Reduce padding to make table more compact */\n",
       "        text-align: left;\n",
       "        border-bottom: 1px solid #888;\n",
       "    }\n",
       "    .nutpie th {\n",
       "        //background-color: #f0f0f0;\n",
       "    }\n",
       "\n",
       "    .nutpie th:nth-child(1) { width: var(--column-width-1); }\n",
       "    .nutpie th:nth-child(2) { width: var(--column-width-2); }\n",
       "    .nutpie th:nth-child(3) { width: var(--column-width-3); }\n",
       "    .nutpie th:nth-child(4) { width: var(--column-width-4); }\n",
       "    .nutpie th:nth-child(5) { width: var(--column-width-5); }\n",
       "\n",
       "    .nutpie progress {\n",
       "        width: 100%;\n",
       "        height: 15px; /* Smaller progress bars */\n",
       "        border-radius: 5px;\n",
       "    }\n",
       "    progress::-webkit-progress-bar {\n",
       "        background-color: #eee;\n",
       "        border-radius: 5px;\n",
       "    }\n",
       "    progress::-webkit-progress-value {\n",
       "        background-color: #5cb85c;\n",
       "        border-radius: 5px;\n",
       "    }\n",
       "    progress::-moz-progress-bar {\n",
       "        background-color: #5cb85c;\n",
       "        border-radius: 5px;\n",
       "    }\n",
       "    .nutpie .progress-cell {\n",
       "        width: 100%;\n",
       "    }\n",
       "\n",
       "    .nutpie p strong { font-size: 16px; font-weight: bold; }\n",
       "\n",
       "    @media (prefers-color-scheme: dark) {\n",
       "        .nutpie {\n",
       "            //color: #ddd;\n",
       "            //background-color: #1e1e1e;\n",
       "            box-shadow: 0 4px 6px rgba(0,0,0,0.2);\n",
       "        }\n",
       "        .nutpie table, .nutpie th, .nutpie td {\n",
       "            border-color: #555;\n",
       "            color: #ccc;\n",
       "        }\n",
       "        .nutpie th {\n",
       "            background-color: #2a2a2a;\n",
       "        }\n",
       "        .nutpie progress::-webkit-progress-bar {\n",
       "            background-color: #444;\n",
       "        }\n",
       "        .nutpie progress::-webkit-progress-value {\n",
       "            background-color: #3178c6;\n",
       "        }\n",
       "        .nutpie progress::-moz-progress-bar {\n",
       "            background-color: #3178c6;\n",
       "        }\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"nutpie\">\n",
       "    <p><strong>Sampler Progress</strong></p>\n",
       "    <p>Total Chains: <span id=\"total-chains\">4</span></p>\n",
       "    <p>Active Chains: <span id=\"active-chains\">4</span></p>\n",
       "    <p>\n",
       "        Finished Chains:\n",
       "        <span id=\"active-chains\">0</span>\n",
       "    </p>\n",
       "    <p>Sampling for now</p>\n",
       "    <p>\n",
       "        Estimated Time to Completion:\n",
       "        <span id=\"eta\">2 minutes</span>\n",
       "    </p>\n",
       "\n",
       "    <progress\n",
       "        id=\"total-progress-bar\"\n",
       "        max=\"10240\"\n",
       "        value=\"790\">\n",
       "    </progress>\n",
       "    <table>\n",
       "        <thead>\n",
       "            <tr>\n",
       "                <th>Progress</th>\n",
       "                <th>Draws</th>\n",
       "                <th>Divergences</th>\n",
       "                <th>Step Size</th>\n",
       "                <th>Gradients/Draw</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody id=\"chain-details\">\n",
       "            \n",
       "                <tr>\n",
       "                    <td class=\"progress-cell\">\n",
       "                        <progress\n",
       "                            max=\"2560\"\n",
       "                            value=\"188\">\n",
       "                        </progress>\n",
       "                    </td>\n",
       "                    <td>188</td>\n",
       "                    <td>0</td>\n",
       "                    <td>0.00</td>\n",
       "                    <td>1023</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td class=\"progress-cell\">\n",
       "                        <progress\n",
       "                            max=\"2560\"\n",
       "                            value=\"221\">\n",
       "                        </progress>\n",
       "                    </td>\n",
       "                    <td>221</td>\n",
       "                    <td>0</td>\n",
       "                    <td>0.00</td>\n",
       "                    <td>1023</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td class=\"progress-cell\">\n",
       "                        <progress\n",
       "                            max=\"2560\"\n",
       "                            value=\"188\">\n",
       "                        </progress>\n",
       "                    </td>\n",
       "                    <td>188</td>\n",
       "                    <td>0</td>\n",
       "                    <td>0.00</td>\n",
       "                    <td>1023</td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr>\n",
       "                    <td class=\"progress-cell\">\n",
       "                        <progress\n",
       "                            max=\"2560\"\n",
       "                            value=\"193\">\n",
       "                        </progress>\n",
       "                    </td>\n",
       "                    <td>193</td>\n",
       "                    <td>0</td>\n",
       "                    <td>0.00</td>\n",
       "                    <td>1023</td>\n",
       "                </tr>\n",
       "            \n",
       "            </tr>\n",
       "        </tbody>\n",
       "    </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<nutpie.sample._BackgroundSampler at 0x35fbd79b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions = norm_hbr.fit_predict(train, test)\n",
    "norm_hbr.fit_predict(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the model \n",
    "\n",
    "The norm_hbr model contains a collection of regression models, one for each response variable. We can inspect those models individually by calling `norm_hbr.regression_models.get(\"{responsevar}\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1670pt\" height=\"690pt\"\n",
       " viewBox=\"0.00 0.00 1670.36 689.86\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 685.86)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-685.86 1666.36,-685.86 1666.36,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>clusterdatapoints (150) x covariates (1)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-328.73C20,-328.73 189,-328.73 189,-328.73 195,-328.73 201,-334.73 201,-340.73 201,-340.73 201,-414.73 201,-414.73 201,-420.73 195,-426.73 189,-426.73 189,-426.73 20,-426.73 20,-426.73 14,-426.73 8,-420.73 8,-414.73 8,-414.73 8,-340.73 8,-340.73 8,-334.73 14,-328.73 20,-328.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.5\" y=\"-335.93\" font-family=\"Times,serif\" font-size=\"14.00\">datapoints (150) x covariates (1)</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>clusterdatapoints (150)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M221,-8C221,-8 359,-8 359,-8 365,-8 371,-14 371,-20 371,-20 371,-532.63 371,-532.63 371,-538.63 365,-544.63 359,-544.63 359,-544.63 221,-544.63 221,-544.63 215,-544.63 209,-538.63 209,-532.63 209,-532.63 209,-20 209,-20 209,-14 215,-8 221,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.75\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"14.00\">datapoints (150)</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>clustercovariates (1)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M391,-316.82C391,-316.82 481,-316.82 481,-316.82 487,-316.82 493,-322.82 493,-328.82 493,-328.82 493,-426.63 493,-426.63 493,-432.63 487,-438.63 481,-438.63 481,-438.63 391,-438.63 391,-438.63 385,-438.63 379,-432.63 379,-426.63 379,-426.63 379,-328.82 379,-328.82 379,-322.82 385,-316.82 391,-316.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"447.88\" y=\"-324.02\" font-family=\"Times,serif\" font-size=\"14.00\">covariates (1)</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>clustersex (2)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M561,-446.63C561,-446.63 863,-446.63 863,-446.63 869,-446.63 875,-452.63 875,-458.63 875,-458.63 875,-661.86 875,-661.86 875,-667.86 869,-673.86 863,-673.86 863,-673.86 561,-673.86 561,-673.86 555,-673.86 549,-667.86 549,-661.86 549,-661.86 549,-458.63 549,-458.63 549,-452.63 555,-446.63 561,-446.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"848.25\" y=\"-453.83\" font-family=\"Times,serif\" font-size=\"14.00\">sex (2)</text>\n",
       "</g>\n",
       "<g id=\"clust5\" class=\"cluster\">\n",
       "<title>clustersite (21)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1122,-446.63C1122,-446.63 1424,-446.63 1424,-446.63 1430,-446.63 1436,-452.63 1436,-458.63 1436,-458.63 1436,-661.86 1436,-661.86 1436,-667.86 1430,-673.86 1424,-673.86 1424,-673.86 1122,-673.86 1122,-673.86 1116,-673.86 1110,-667.86 1110,-661.86 1110,-661.86 1110,-458.63 1110,-458.63 1110,-452.63 1116,-446.63 1122,-446.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"1405.5\" y=\"-453.83\" font-family=\"Times,serif\" font-size=\"14.00\">site (21)</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<path fill=\"lightgrey\" stroke=\"black\" d=\"M181,-418.73C181,-418.73 151,-418.73 151,-418.73 145,-418.73 139,-412.73 139,-406.73 139,-406.73 139,-373.23 139,-373.23 139,-367.23 145,-361.23 151,-361.23 151,-361.23 181,-361.23 181,-361.23 187,-361.23 193,-367.23 193,-373.23 193,-373.23 193,-406.73 193,-406.73 193,-412.73 187,-418.73 181,-418.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-401.43\" font-family=\"Times,serif\" font-size=\"14.00\">X</text>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-384.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"166\" y=\"-368.43\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n",
       "</g>\n",
       "<!-- mu_samples -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>mu_samples</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"363.12,-308.82 272.88,-308.82 272.88,-251.32 363.12,-251.32 363.12,-308.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-291.52\" font-family=\"Times,serif\" font-size=\"14.00\">mu_samples</text>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-275.02\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-258.52\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;mu_samples -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>X&#45;&gt;mu_samples</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.26,-360.9C181.51,-345.91 191.17,-328.25 205,-316.82 221.05,-303.55 242.07,-295.18 261.62,-289.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.25,-293.37 271.13,-287.59 260.59,-286.57 262.25,-293.37\"/>\n",
       "</g>\n",
       "<!-- y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>y</title>\n",
       "<path fill=\"lightgrey\" stroke=\"black\" d=\"M335,-98C335,-98 305,-98 305,-98 299,-98 293,-92 293,-86 293,-86 293,-52.5 293,-52.5 293,-46.5 299,-40.5 305,-40.5 305,-40.5 335,-40.5 335,-40.5 341,-40.5 347,-46.5 347,-52.5 347,-52.5 347,-86 347,-86 347,-92 341,-98 335,-98\"/>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-80.7\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-64.2\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-47.7\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n",
       "</g>\n",
       "<!-- y_pred -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>y_pred</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"320\" cy=\"-174.66\" rx=\"41.01\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-186.11\" font-family=\"Times,serif\" font-size=\"14.00\">y_pred</text>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-169.61\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"320\" y=\"-153.11\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- y_pred&#45;&gt;y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>y_pred&#45;&gt;y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320,-133.68C320,-125.83 320,-117.6 320,-109.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"323.5,-109.79 320,-99.79 316.5,-109.79 323.5,-109.79\"/>\n",
       "</g>\n",
       "<!-- mu_samples&#45;&gt;y_pred -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>mu_samples&#45;&gt;y_pred</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.54,-251.08C318.69,-243.6 318.85,-235.27 319.01,-226.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"322.5,-227.28 319.2,-217.21 315.5,-227.14 322.5,-227.28\"/>\n",
       "</g>\n",
       "<!-- sex_data -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>sex_data</title>\n",
       "<path fill=\"lightgrey\" stroke=\"black\" d=\"M268.62,-536.63C268.62,-536.63 229.38,-536.63 229.38,-536.63 223.38,-536.63 217.38,-530.63 217.38,-524.63 217.38,-524.63 217.38,-491.13 217.38,-491.13 217.38,-485.13 223.38,-479.13 229.38,-479.13 229.38,-479.13 268.62,-479.13 268.62,-479.13 274.62,-479.13 280.62,-485.13 280.62,-491.13 280.62,-491.13 280.62,-524.63 280.62,-524.63 280.62,-530.63 274.62,-536.63 268.62,-536.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-519.33\" font-family=\"Times,serif\" font-size=\"14.00\">sex_data</text>\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-502.83\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-486.33\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n",
       "</g>\n",
       "<!-- intercept_mu -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>intercept_mu</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"363.12,-418.73 272.88,-418.73 272.88,-361.23 363.12,-361.23 363.12,-418.73\"/>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-401.43\" font-family=\"Times,serif\" font-size=\"14.00\">intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-384.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"318\" y=\"-368.43\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- sex_data&#45;&gt;intercept_mu -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>sex_data&#45;&gt;intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M265.7,-478.83C274.62,-463.85 285.72,-445.2 295.4,-428.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"298.33,-430.86 300.44,-420.48 292.31,-427.28 298.33,-430.86\"/>\n",
       "</g>\n",
       "<!-- intercept_mu&#45;&gt;mu_samples -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>intercept_mu&#45;&gt;mu_samples</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318,-360.91C318,-348.54 318,-333.8 318,-320.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"321.5,-320.51 318,-310.51 314.5,-320.51 321.5,-320.51\"/>\n",
       "</g>\n",
       "<!-- site_data -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>site_data</title>\n",
       "<path fill=\"lightgrey\" stroke=\"black\" d=\"M351,-536.63C351,-536.63 311,-536.63 311,-536.63 305,-536.63 299,-530.63 299,-524.63 299,-524.63 299,-491.13 299,-491.13 299,-485.13 305,-479.13 311,-479.13 311,-479.13 351,-479.13 351,-479.13 357,-479.13 363,-485.13 363,-491.13 363,-491.13 363,-524.63 363,-524.63 363,-530.63 357,-536.63 351,-536.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"331\" y=\"-519.33\" font-family=\"Times,serif\" font-size=\"14.00\">site_data</text>\n",
       "<text text-anchor=\"middle\" x=\"331\" y=\"-502.83\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"331\" y=\"-486.33\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n",
       "</g>\n",
       "<!-- site_data&#45;&gt;intercept_mu -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>site_data&#45;&gt;intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M327.85,-478.83C326.22,-464.27 324.2,-446.25 322.41,-430.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.92,-430.23 321.33,-420.68 318.97,-431.01 325.92,-430.23\"/>\n",
       "</g>\n",
       "<!-- slope_mu -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>slope_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"436\" cy=\"-389.98\" rx=\"48.97\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-401.43\" font-family=\"Times,serif\" font-size=\"14.00\">slope_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-384.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"436\" y=\"-368.43\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- slope_mu&#45;&gt;mu_samples -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>slope_mu&#45;&gt;mu_samples</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M410.65,-354.69C400.37,-342 387.89,-328 375,-316.82 374.1,-316.03 373.17,-315.25 372.23,-314.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"374.69,-311.96 364.63,-308.64 370.43,-317.51 374.69,-311.96\"/>\n",
       "</g>\n",
       "<!-- mu_intercept_mu -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>mu_intercept_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"461\" cy=\"-507.88\" rx=\"79.73\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-519.33\" font-family=\"Times,serif\" font-size=\"14.00\">mu_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-502.83\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-486.33\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- mu_intercept_mu&#45;&gt;intercept_mu -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>mu_intercept_mu&#45;&gt;intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M418.4,-473.43C404.5,-462.42 389.04,-450.07 375,-438.63 370.07,-434.62 364.92,-430.38 359.82,-426.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"362.43,-423.77 352.5,-420.06 357.95,-429.15 362.43,-423.77\"/>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"544\" cy=\"-389.98\" rx=\"41.01\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-401.43\" font-family=\"Times,serif\" font-size=\"14.00\">sigma</text>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-384.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-368.43\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- sigma_samples -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>sigma_samples</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"537,-308.82 437,-308.82 437,-251.32 537,-251.32 537,-308.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"487\" y=\"-291.52\" font-family=\"Times,serif\" font-size=\"14.00\">sigma_samples</text>\n",
       "<text text-anchor=\"middle\" x=\"487\" y=\"-275.02\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"487\" y=\"-258.52\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;sigma_samples -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;sigma_samples</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M525.18,-353.34C519.37,-342.35 512.95,-330.19 507.06,-319.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.3,-317.69 502.54,-310.49 504.12,-320.96 510.3,-317.69\"/>\n",
       "</g>\n",
       "<!-- sigma_samples&#45;&gt;y_pred -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>sigma_samples&#45;&gt;y_pred</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M441.81,-251.08C417.7,-236.15 388.14,-217.85 364.19,-203.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.26,-200.19 355.92,-197.9 362.58,-206.14 366.26,-200.19\"/>\n",
       "</g>\n",
       "<!-- sex_sigma_intercept_mu -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>sex_sigma_intercept_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"992\" cy=\"-625.2\" rx=\"107.83\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"992\" y=\"-636.65\" font-family=\"Times,serif\" font-size=\"14.00\">sex_sigma_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"992\" y=\"-620.15\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"992\" y=\"-603.65\" font-family=\"Times,serif\" font-size=\"14.00\">HalfNormal</text>\n",
       "</g>\n",
       "<!-- sex_offset_intercept_mu -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>sex_offset_intercept_mu</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"787.12,-536.63 636.88,-536.63 636.88,-479.13 787.12,-479.13 787.12,-536.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"712\" y=\"-519.33\" font-family=\"Times,serif\" font-size=\"14.00\">sex_offset_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"712\" y=\"-502.83\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"712\" y=\"-486.33\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- sex_sigma_intercept_mu&#45;&gt;sex_offset_intercept_mu -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sex_sigma_intercept_mu&#45;&gt;sex_offset_intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M919.89,-594.5C880.48,-578.27 831.59,-558.14 791.12,-541.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"792.47,-538.24 781.89,-537.67 789.8,-544.71 792.47,-538.24\"/>\n",
       "</g>\n",
       "<!-- site_sigma_intercept_mu -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>site_sigma_intercept_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1554\" cy=\"-625.2\" rx=\"108.36\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1554\" y=\"-636.65\" font-family=\"Times,serif\" font-size=\"14.00\">site_sigma_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"1554\" y=\"-620.15\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1554\" y=\"-603.65\" font-family=\"Times,serif\" font-size=\"14.00\">HalfNormal</text>\n",
       "</g>\n",
       "<!-- site_offset_intercept_mu -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>site_offset_intercept_mu</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1348.5,-536.63 1197.5,-536.63 1197.5,-479.13 1348.5,-479.13 1348.5,-536.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"1273\" y=\"-519.33\" font-family=\"Times,serif\" font-size=\"14.00\">site_offset_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"1273\" y=\"-502.83\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1273\" y=\"-486.33\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- site_sigma_intercept_mu&#45;&gt;site_offset_intercept_mu -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>site_sigma_intercept_mu&#45;&gt;site_offset_intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1481.64,-594.5C1441.99,-578.24 1392.8,-558.05 1352.14,-541.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1353.71,-538.22 1343.13,-537.67 1351.05,-544.7 1353.71,-538.22\"/>\n",
       "</g>\n",
       "<!-- normalized_sex_offset_intercept_mu -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>normalized_sex_offset_intercept_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"712\" cy=\"-625.2\" rx=\"154.5\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"712\" y=\"-636.65\" font-family=\"Times,serif\" font-size=\"14.00\">normalized_sex_offset_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"712\" y=\"-620.15\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"712\" y=\"-603.65\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- normalized_sex_offset_intercept_mu&#45;&gt;sex_offset_intercept_mu -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>normalized_sex_offset_intercept_mu&#45;&gt;sex_offset_intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M712,-584.19C712,-572.48 712,-559.7 712,-548.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"715.5,-548.36 712,-538.36 708.5,-548.36 715.5,-548.36\"/>\n",
       "</g>\n",
       "<!-- sex_offset_intercept_mu&#45;&gt;intercept_mu -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>sex_offset_intercept_mu&#45;&gt;intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M650.25,-478.77C620.57,-466.6 584.11,-453.58 550,-446.63 511.85,-438.87 411.28,-452.75 375,-438.63 367.31,-435.64 359.91,-431.17 353.13,-426.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.46,-423.54 345.48,-419.99 351.08,-428.99 355.46,-423.54\"/>\n",
       "</g>\n",
       "<!-- normalized_site_offset_intercept_mu -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>normalized_site_offset_intercept_mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1273\" cy=\"-625.2\" rx=\"155.03\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"1273\" y=\"-636.65\" font-family=\"Times,serif\" font-size=\"14.00\">normalized_site_offset_intercept_mu</text>\n",
       "<text text-anchor=\"middle\" x=\"1273\" y=\"-620.15\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"1273\" y=\"-603.65\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- normalized_site_offset_intercept_mu&#45;&gt;site_offset_intercept_mu -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>normalized_site_offset_intercept_mu&#45;&gt;site_offset_intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1273,-584.19C1273,-572.48 1273,-559.7 1273,-548.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1276.5,-548.36 1273,-538.36 1269.5,-548.36 1276.5,-548.36\"/>\n",
       "</g>\n",
       "<!-- site_offset_intercept_mu&#45;&gt;intercept_mu -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>site_offset_intercept_mu&#45;&gt;intercept_mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1197.1,-492.14C1118.02,-477.52 990.36,-455.99 879,-446.63 851.09,-444.29 401.25,-448.4 375,-438.63 367.19,-435.73 359.69,-431.25 352.84,-426.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.09,-423.51 345.11,-419.95 350.7,-428.95 355.09,-423.51\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x3273b7d10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model: HBR = norm_hbr.regression_models.get(\"rh_MeanThickness_thickness\")  # type: ignore\n",
    "model.pymc_model.to_graphviz()  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the arviz library to inspect the posterior samples (trace) of the model. Here we only use the 'plot_trace' function to inspect the trace of the model, but there are many other useful functions available. If you are not familiar with arviz, we recommend checking out the [arviz documentation](https://arviz-devs.github.io/arviz/index.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = model.idata  # type: ignore\n",
    "\n",
    "plt.tight_layout()\n",
    "az.plot_trace(\n",
    "    idata.posterior,\n",
    "    var_names=[\n",
    "        \"~mu_samples\",\n",
    "        \"~sigma_samples\",\n",
    "        \"~epsilon_samples\",\n",
    "        \"~delta_samples\",\n",
    "        \"~intercept_mu\",\n",
    "        \"~scaled_site_offset_intercept_mu\",\n",
    "        \"~scaled_sex_offset_intercept_mu\",\n",
    "    ],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Calling `predict` will extend the predict_data object with a number of useful arrays.\n",
    "1. `measures`: DataArray, which contains a number of evaluation statistics. \n",
    "1. `zscores`: the predicted z-scores for each datapoint.  \n",
    "1. `centiles`: the predicted centiles of variation evaluated at each covariate in the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test.measures.to_pandas().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets with a zscores DataArray will have the `.plot_qq()` function available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test.zscores.to_pandas())  # the zscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test.centiles.to_dataframe().unstack(level=[\"response_vars\", \"cdf\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_qq(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `plot_centiles()` can be called as a function of the model. A synthetic dataset is created internally, so we need to pass the original dataset (`train` in this case) as a template. We also need to pass which covariate is to be plotted on the x-axis, and the batch-effects for which the centiles are to be plotted. \n",
    "\n",
    "The lines correspond to the CDF values of: [0.05, 0.25, 0.5, 0.75, 0.95]. It is also possible to pass a list of CDF values to plot.\n",
    "\n",
    "It may seem strange that the centiles do not match the plotted data, but that is because the centiles are calculated for a single batch effect, and it is superimposed on the full dataset. The blue markers correspond to the data for which the centiles are calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centiles(\n",
    "    norm_hbr,\n",
    "    train,\n",
    "    covariate=\"age\",\n",
    "    show_data=True,\n",
    "    hue_data=\"sex\",\n",
    "    markers_data=\"site\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of 0.1587 and 0.8413 correspond to a standard deviation of -1 and 1. We plot the centiles again for these values, and we also highlight a specific site. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centiles(\n",
    "    norm_hbr,\n",
    "    train,\n",
    "    covariate=\"age\",\n",
    "    cummul_densities=[0.1587, 0.8413],\n",
    "    show_data=True,\n",
    "    batch_effects={\"site\": [\"Beijing_Zang\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer\n",
    "\n",
    "If we transfer to new dataset, we use the samples from the posterior to derive priors for a new model. That new model is then fitted on the new dataset. Our new model will not work on the old data. To give some extra control over the fit, we let the `freedom` parameter control the variance of the derived factorized posterior. Here we set it to something small (1e-4) to create a spike prior on the model parameters, to ensure that we do not 'forget' about what we learned from the original data. If we have a very large new dataset, we can set the freedom parameter to something bigger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcntoolkit.normative_model.norm_factory import load_normative_model\n",
    "\n",
    "save_dir = \"resources/hbr/save_dir\"\n",
    "model = load_normative_model(save_dir)\n",
    "\n",
    "transfered_model = model.transfer_predict(\n",
    "    transfer_train, transfer_test, freedom=1e-4, nuts_sampler=\"nutpie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfered_model.predict(transfer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save, load, predict, and plot just as before. \n",
    "\n",
    "If the orinal save directory path was `{path}/{save_dir}`, then the transfered model's save directory path will be `{path}/{save_dir}_tansfer`, and the same holds for the log dir path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend\n",
    "\n",
    "Extending a model on new data amounts to generating synthetic data according to the learned distribution, merging that with the new data, and fitting a new model on that merged dataset. This enables true federated learning, because the original data does not need to be shipped with the model to extend it to a new dataset. \n",
    "\n",
    "Because this is an extended model, we can make predictions on all sites, even those that were only present in the original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"resources/hbr/save_dir\"\n",
    "from pcntoolkit.normative_model.norm_factory import load_normative_model\n",
    "\n",
    "model = load_normative_model(save_dir)\n",
    "\n",
    "extended_model = model.extend_predict(transfer_train, transfer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, now you have seen how to:\n",
    "- Use the NormData class to load in your data\n",
    "- Create and fit a normative model\n",
    "- Get the evaluation statistics, and create some useful plots\n",
    "- Transfer the model to another dataset\n",
    "- Extend the model to another dataset\n",
    "\n",
    "We hope this tutorial was useful. If you have any questions or remarks, please let us know on GitHub. Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_refactor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
