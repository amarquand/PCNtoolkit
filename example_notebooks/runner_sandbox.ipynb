{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Users'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m resources_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/stijndeboer/Projects/PCN/PCNtoolkit/example_notebooks/resources\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(resources_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# If you are running this notebook for the first time, you need to download the dataset from github.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# If you have already downloaded the dataset, you can comment out the following line\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# pd.read_csv(\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     \"https://raw.githubusercontent.com/predictive-clinical-neuroscience/PCNtoolkit-demo/refs/heads/main/data/fcon1000.csv\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# ).to_csv(os.path.join(data_dir, \"fcon1000.csv\"), index=False)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfcon1000.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Users'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pcntoolkit.dataio.norm_data import NormData\n",
    "from pcntoolkit.normative_model.norm_conf import NormConf\n",
    "from pcntoolkit.normative_model.norm_hbr import NormHBR\n",
    "from pcntoolkit.regression_model.hbr.hbr_conf import HBRConf\n",
    "from pcntoolkit.regression_model.hbr.prior import make_prior\n",
    "from pcntoolkit.util.runner import Runner\n",
    "\n",
    "resources_dir = \"/Users/stijndeboer/Projects/PCN/PCNtoolkit/example_notebooks/resources\"\n",
    "data_dir = os.path.join(resources_dir, \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# If you are running this notebook for the first time, you need to download the dataset from github.\n",
    "# If you have already downloaded the dataset, you can comment out the following line\n",
    "\n",
    "# pd.read_csv(\n",
    "#     \"https://raw.githubusercontent.com/predictive-clinical-neuroscience/PCNtoolkit-demo/refs/heads/main/data/fcon1000.csv\"\n",
    "# ).to_csv(os.path.join(data_dir, \"fcon1000.csv\"), index=False)\n",
    "data = pd.read_csv(os.path.join(data_dir, \"fcon1000.csv\"))\n",
    "covariates = [\"age\"]\n",
    "batch_effects = [\"sex\", \"site\"]\n",
    "response_vars = [\"rh_MeanThickness_thickness\", \"WM-hypointensities\"]\n",
    "norm_data = NormData.from_dataframe(\n",
    "    name=\"full\",\n",
    "    dataframe=data,\n",
    "    covariates=[\"age\"],\n",
    "    batch_effects=[\"sex\", \"site\"],\n",
    "    response_vars=[\"rh_MeanThickness_thickness\", \"WM-hypointensities\"],\n",
    ")\n",
    "\n",
    "# Leave two sites out for doing transfer and extend later\n",
    "transfer_sites = [\"Milwaukee_b\", \"Oulu\"]\n",
    "transfer_data, fit_data = norm_data.split_batch_effects({\"site\": transfer_sites}, names=(\"transfer\", \"fit\"))\n",
    "\n",
    "# Split into train and test sets\n",
    "train, test = fit_data.train_test_split()\n",
    "transfer_train, transfer_test = transfer_data.train_test_split()\n",
    "\n",
    "# Create a NormConf object\n",
    "sandbox_dir = os.path.join(resources_dir, \"hbr_runner_sandbox\")\n",
    "os.makedirs(sandbox_dir, exist_ok=True)\n",
    "norm_conf = NormConf(\n",
    "    savemodel=True,\n",
    "    saveresults=True,\n",
    "    save_dir=save_dir,\n",
    "    inscaler=\"standardize\",\n",
    "    outscaler=\"standardize\",\n",
    "    basis_function=\"bspline\",\n",
    "    basis_function_kwargs={\"order\": 3, \"nknots\": 5},\n",
    ")\n",
    "\n",
    "mu = make_prior(\n",
    "    linear=True,\n",
    "    slope=make_prior(dist_params = (0.0, 10.)),\n",
    "    intercept=make_prior(\n",
    "        random=True,\n",
    "        sigma=make_prior(dist_name=\"HalfCauchy\", dist_params=(0.5,)),\n",
    "        mu=make_prior(dist_name=\"Normal\", dist_params=(0.0, 1.0)),\n",
    "    ),\n",
    ")\n",
    "\n",
    "sigma = make_prior(\n",
    "    linear=True,\n",
    "    slope=make_prior(dist_params = (0.0, 10.0)),\n",
    "    intercept=make_prior(\n",
    "        random=True,\n",
    "        sigma=make_prior(dist_name=\"HalfCauchy\", dist_params=(0.5,)),\n",
    "        mu=make_prior(dist_name=\"Normal\", dist_params=(1.0, 1.0)),\n",
    "    ),\n",
    "    mapping=\"softplus\",\n",
    "    mapping_params=(0.0, 3.0),\n",
    ")\n",
    "\n",
    "epsilon = make_prior(\n",
    "    linear=True,\n",
    "    slope=make_prior(dist_params = (0.0, 1.0)),\n",
    "    intercept=make_prior(\n",
    "        random=True,\n",
    "        sigma=make_prior(dist_name=\"HalfCauchy\", dist_params=(0.5,)),\n",
    "        mu=make_prior(dist_name=\"Normal\", dist_params=(0.0, 0.5)),\n",
    "    ),\n",
    ")\n",
    "\n",
    "delta = make_prior(\n",
    "    linear=True,\n",
    "    slope=make_prior(dist_params = (0.0, 1.0)),\n",
    "    intercept=make_prior(\n",
    "        random=True,\n",
    "        sigma=make_prior(dist_name=\"HalfCauchy\", dist_params=(0.5,)),\n",
    "        mu=make_prior(dist_name=\"Normal\", dist_params=(1.0, 0.5)),\n",
    "    ),\n",
    "    mapping=\"softplus\",\n",
    "    mapping_params=(0.0, 2.0, 0.5),\n",
    ")\n",
    "\n",
    "\n",
    "# Configure the HBRConf object\n",
    "hbr_conf = HBRConf(\n",
    "    draws=1500,\n",
    "    tune=500,\n",
    "    chains=4,\n",
    "    pymc_cores=16,\n",
    "    likelihood=\"Normal\",\n",
    "    mu=mu,\n",
    "    sigma=sigma,\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    nuts_sampler=\"nutpie\",\n",
    ")\n",
    "\n",
    "new_hbr_model = NormHBR(norm_conf=norm_conf, reg_conf=hbr_conf)\n",
    "\n",
    "runner = Runner(\n",
    "    cross_validate=False,\n",
    "    parallelize=True,\n",
    "    time_limit=\"15:00:00\",\n",
    "    job_type=\"slurm\",\n",
    "    n_jobs=2,\n",
    "    log_dir=os.path.join(sandbox_dir, \"log_dir\"),\n",
    "    temp_dir=os.path.join(sandbox_dir, \"temp_dir\"),\n",
    ")\n",
    "\n",
    "runner.fit_predict(new_hbr_model, train, test, observe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 26284 - Loading runner state from /Users/stijndeboer/Projects/PCN/PCNtoolkit/example_notebooks/resources/hbr_runner_sandbox/temp_dir/runner_state.json\n",
      "Process: 26284 - No python path specified. Using interpreter path of current process: /opt/anaconda3/envs/dev_refactor_2/bin/python\n",
      "Process: 26284 - Runner loaded\n",
      "--------------------------------------------\n",
      "Active jobs: 2\n",
      "Finished jobs: 0\n",
      "Failed jobs: 0\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.util.runner.Runner at 0x16c1d69f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 26284 - Loading runner state from /Users/stijndeboer/Projects/PCN/PCNtoolkit/example_notebooks/resources/hbr_runner_sandbox/temp_dir/runner_state.json\n",
      "Process: 26284 - No python path specified. Using interpreter path of current process: /opt/anaconda3/envs/dev_refactor_2/bin/python\n",
      "Process: 26284 - Runner loaded\n",
      "--------------------------------------------\n",
      "Active jobs: 0\n",
      "Finished jobs: 2\n",
      "Failed jobs: 0\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.util.runner.Runner at 0x173ae4890>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Runner.load(\"/Users/stijndeboer/Projects/PCN/PCNtoolkit/example_notebooks/resources/hbr_runner_sandbox/temp_dir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_refactor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
