

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>utils &mdash; Predictive Clinical Neuroscience Toolkit 0.20 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/tabs.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pages/css/pcntoolkit_tabs.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pages/css/pcntoolkit.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pages/css/pcntoolkit_nomaxwidth.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/pcn-logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/installation.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/pcntoolkit_background.html">PCNtoolkit Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/pcntoolkit_background.html#intro-to-normative-modelling">Intro to normative modelling</a></li>
</ul>
<p class="caption"><span class="caption-text">Function Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modindex.html">Module Index</a></li>
</ul>
<p class="caption"><span class="caption-text">Current Events</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/updates.html">Updates</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_CPC2020.html">Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_ROIcorticalthickness.html">Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_HBR.html">Hierarchical Bayesian Regressian</a></li>
</ul>
<p class="caption"><span class="caption-text">Other Useful Stuff</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/FAQs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/citing.html">How to cite PCNtoolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/acknowledgements.html">Acknowledgements</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Predictive Clinical Neuroscience Toolkit</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Module code</a> &raquo;</li>
        
      <li>utils</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for utils</h1><div class="highlight"><pre>
<span></span>from __future__ import print_function

import os
import numpy as np
from scipy import stats
from subprocess import call
from scipy.stats import genextreme, norm
from six import with_metaclass
from abc import ABCMeta, abstractmethod
import pickle
import matplotlib.pyplot as plt
import pandas as pd
import bspline
from bspline import splinelab
from sklearn.datasets import make_regression
import pymc3 as pm

# -----------------
# Utility functions
# -----------------
<div class="viewcode-block" id="create_poly_basis"><a class="viewcode-back" href="../modindex.html#utils.create_poly_basis">[docs]</a>def create_poly_basis(X, dimpoly):
    &quot;&quot;&quot; compute a polynomial basis expansion of the specified order&quot;&quot;&quot;
    
    if len(X.shape) == 1:
        X = X[:, np.newaxis]
    D = X.shape[1]
    Phi = np.zeros((X.shape[0], D*dimpoly))
    colid = np.arange(0, D)
    for d in range(1, dimpoly+1):
        Phi[:, colid] = X ** d
        colid += D
        
    return Phi</div>

<div class="viewcode-block" id="create_bspline_basis"><a class="viewcode-back" href="../modindex.html#utils.create_bspline_basis">[docs]</a>def create_bspline_basis(xmin, xmax, p = 3, nknots = 5):
    &quot;&quot;&quot; compute a Bspline basis set where:
        
        :param p: order of spline (3 = cubic)
        :param nknots: number of knots (endpoints only counted once)
    &quot;&quot;&quot;
    
    knots = np.linspace(xmin, xmax, nknots)
    k = splinelab.augknt(knots, p)       # pad the knot vector
    B = bspline.Bspline(k, p) 
    return B</div>

<div class="viewcode-block" id="squared_dist"><a class="viewcode-back" href="../modindex.html#utils.squared_dist">[docs]</a>def squared_dist(x, z=None):
    &quot;&quot;&quot; compute sum((x-z) ** 2) for all vectors in a 2d array&quot;&quot;&quot;

    # do some basic checks
    if z is None:
        z = x
    if len(x.shape) == 1:
        x = x[:, np.newaxis]
    if len(z.shape) == 1:
        z = z[:, np.newaxis]

    nx, dx = x.shape
    nz, dz = z.shape
    if dx != dz:
        raise ValueError(&quot;&quot;&quot;
                Cannot compute distance: vectors have different length&quot;&quot;&quot;)

    # mean centre for numerical stability
    m = np.mean(np.vstack((np.mean(x, axis=0), np.mean(z, axis=0))), axis=0)
    x = x - m
    z = z - m

    xx = np.tile(np.sum((x*x), axis=1)[:, np.newaxis], (1, nz))
    zz = np.tile(np.sum((z*z), axis=1), (nx, 1))

    dist = (xx - 2*x.dot(z.T) + zz)

    return dist</div>


<div class="viewcode-block" id="compute_pearsonr"><a class="viewcode-back" href="../modindex.html#utils.compute_pearsonr">[docs]</a>def compute_pearsonr(A, B):
    &quot;&quot;&quot; Manually computes the Pearson correlation between two matrices.

        Basic usage::

        compute_pearsonr(A, B)

        where

        :param A: an N * M data array
        :param cov: an N * M array

        :returns Rho: N dimensional vector of correlation coefficients
        :returns ys2: N dimensional vector of p-values

        Notes::

        This function is useful when M is large and only the diagonal entries
        of the resulting correlation matrix are of interest. This function
        does not compute the full correlation matrix as an intermediate step&quot;&quot;&quot;

    # N = A.shape[1]
    N = A.shape[0]

    # first mean centre
    Am = A - np.mean(A, axis=0)
    Bm = B - np.mean(B, axis=0)
    # then normalize
    An = Am / np.sqrt(np.sum(Am**2, axis=0))
    Bn = Bm / np.sqrt(np.sum(Bm**2, axis=0))
    del(Am, Bm)

    Rho = np.sum(An * Bn, axis=0)
    del(An, Bn)

    # Fisher r-to-z
    Zr = (np.arctanh(Rho) - np.arctanh(0)) * np.sqrt(N - 3)
    N = stats.norm()
    pRho = 2*N.cdf(-np.abs(Zr))
    # pRho = 1-N.cdf(Zr)
    
    return Rho, pRho</div>

<div class="viewcode-block" id="explained_var"><a class="viewcode-back" href="../modindex.html#utils.explained_var">[docs]</a>def explained_var(ytrue, ypred):
    &quot;&quot;&quot; Computes the explained variance of predicted values.

        Basic usage::

        exp_var = explained_var(ytrue, ypred)

        where

        :ytrue: n*p matrix of true values where n is the number of samples 
                and p is the number of features. 
        :ypred: n*p matrix of predicted values where n is the number of samples 
                and p is the number of features. 

        :returns exp_var: p dimentional vector of explained variances for each feature.
        
     &quot;&quot;&quot;

    exp_var = 1 - (ytrue - ypred).var(axis = 0) / ytrue.var(axis = 0)
    
    return exp_var</div>

<div class="viewcode-block" id="compute_MSLL"><a class="viewcode-back" href="../modindex.html#utils.compute_MSLL">[docs]</a>def compute_MSLL(ytrue, ypred, ypred_var, train_mean = None, train_var = None): 
    &quot;&quot;&quot; Computes the MSLL or MLL (not standardized) if &#39;train_mean&#39; and &#39;train_var&#39; are None.
    
        Basic usage::
            
        MSLL = compute_MSLL(ytrue, ypred, ytrue_sig, noise_variance, train_mean, train_var)
        
        where
        
        :ytrue          : n*p matrix of true values where n is the number of samples 
                          and p is the number of features. 
        :ypred          : n*p matrix of predicted values where n is the number of samples 
                          and p is the number of features. 
        :ypred_var      : n*p matrix of summed noise variances and prediction variances where n is the number of samples 
                          and p is the number of features.
        :train_mean     : p dimensional vector of mean values of the training data for each feature.
        :train_var      : p dimensional vector of covariances of the training data for each feature.
        
        :returns loss   : p dimensional vector of MSLL or MLL for each feature.
    
    &quot;&quot;&quot;
    
    if train_mean is not None and train_var is not None: 
        
        # make sure y_train_mean and y_train_sig have right dimensions (subjects x voxels):
        Y_train_mean = np.repeat(train_mean, ytrue.shape[0], axis = 0)
        Y_train_sig = np.repeat(train_var, ytrue.shape[0], axis = 0)
        
        # compute MSLL:
        loss = np.mean(0.5 * np.log(2 * np.pi * ypred_var) + (ytrue - ypred)**2 / (2 * ypred_var) - 
                       0.5 * np.log(2 * np.pi * Y_train_sig) - (ytrue - Y_train_mean)**2 / (2 * Y_train_sig), axis = 0)
        
    else:   
        # compute MLL:
        loss = np.mean(0.5 * np.log(2 * np.pi * ypred_var) + (ytrue - ypred)**2 / (2 * ypred_var), axis = 0)
        
    return loss</div>

<div class="viewcode-block" id="WarpBase"><a class="viewcode-back" href="../modindex.html#utils.WarpBase">[docs]</a>class WarpBase(with_metaclass(ABCMeta)):
    &quot;&quot;&quot; Base class for likelihood warping following:
        Rios and Torab (2019) Compositionally-warped Gaussian processes
        https://www.sciencedirect.com/science/article/pii/S0893608019301856

        All Warps must define the following methods::

            Warp.get_n_params() - return number of parameters
            Warp.f() - warping function (Non-Gaussian field -&gt; Gaussian)
            Warp.invf() - inverse warp
            Warp.df() - derivatives
            Warp.warp_predictions() - compute predictive distribution
    &quot;&quot;&quot;

    def __init__(self):
        self.n_params = np.nan

<div class="viewcode-block" id="WarpBase.get_n_params"><a class="viewcode-back" href="../modindex.html#utils.WarpBase.get_n_params">[docs]</a>    def get_n_params(self):
        &quot;&quot;&quot; Report the number of parameters required &quot;&quot;&quot;

        assert not np.isnan(self.n_params), \
            &quot;Warp function not initialised&quot;

        return self.n_params</div>

<div class="viewcode-block" id="WarpBase.warp_predictions"><a class="viewcode-back" href="../modindex.html#utils.WarpBase.warp_predictions">[docs]</a>    def warp_predictions(self, mu, s2, param, percentiles=[0.025, 0.975]):
        &quot;&quot;&quot; Compute the warped predictions from a gaussian predictive
            distribution, specifed by a mean (mu) and variance (s2)
            
            :param mu: Gassian predictive mean 
            :param s2: Predictive variance
            :param param: warping parameters
            :param percentiles: Desired percentiles of the warped likelihood

            :returns: * median - median of the predictive distribution
                      * pred_interval - predictive interval(s)
        &quot;&quot;&quot;

        # Compute percentiles of a standard Gaussian
        N = norm
        Z = N.ppf(percentiles)
        
        # find the median (using mu = median)
        median = self.invf(mu, param)

        # compute the predictive intervals (non-stationary)
        pred_interval = np.zeros((len(mu), len(Z)))
        for i, z in enumerate(Z):
            pred_interval[:,i] = self.invf(mu + np.sqrt(s2)*z, param)

        return median, pred_interval</div>
    
<div class="viewcode-block" id="WarpBase.f"><a class="viewcode-back" href="../modindex.html#utils.WarpBase.f">[docs]</a>    @abstractmethod
    def f(self, x, param):
        &quot;&quot;&quot; Evaluate the warping function (mapping non-Gaussian respone 
            variables to Gaussian variables)&quot;&quot;&quot;</div>

<div class="viewcode-block" id="WarpBase.invf"><a class="viewcode-back" href="../modindex.html#utils.WarpBase.invf">[docs]</a>    @abstractmethod
    def invf(self, y, param):
        &quot;&quot;&quot; Evaluate the warping function (mapping Gaussian latent variables 
            to non-Gaussian response variables) &quot;&quot;&quot;</div>

<div class="viewcode-block" id="WarpBase.df"><a class="viewcode-back" href="../modindex.html#utils.WarpBase.df">[docs]</a>    @abstractmethod
    def df(self, x, param):
        &quot;&quot;&quot; Return the derivative of the warp, dw(x)/dx &quot;&quot;&quot;</div></div>

<div class="viewcode-block" id="WarpAffine"><a class="viewcode-back" href="../modindex.html#utils.WarpAffine">[docs]</a>class WarpAffine(WarpBase):
    &quot;&quot;&quot; Affine warp
        y = a + b*x
    &quot;&quot;&quot;

    def __init__(self):
        self.n_params = 2
    
    def _get_params(self, param):
        if len(param) != self.n_params:
            raise(ValueError, 
                  &#39;number of parameters must be &#39; + str(self.n_params))
        return param[0], param[1]

<div class="viewcode-block" id="WarpAffine.f"><a class="viewcode-back" href="../modindex.html#utils.WarpAffine.f">[docs]</a>    def f(self, x, params):
        a, b = self._get_params(params)
        
        y = a + b*x 
        return y</div>
    
<div class="viewcode-block" id="WarpAffine.invf"><a class="viewcode-back" href="../modindex.html#utils.WarpAffine.invf">[docs]</a>    def invf(self, y, params):
        a, b = self._get_params(params)
        
        x = (y - a) / b 
       
        return x</div>

<div class="viewcode-block" id="WarpAffine.df"><a class="viewcode-back" href="../modindex.html#utils.WarpAffine.df">[docs]</a>    def df(self, x, params):
        a, b = self._get_params(params)
        
        df = np.ones(x.shape)*b
        return df</div></div>

<div class="viewcode-block" id="WarpBoxCox"><a class="viewcode-back" href="../modindex.html#utils.WarpBoxCox">[docs]</a>class WarpBoxCox(WarpBase):
    &quot;&quot;&quot; Box cox transform having a single parameter (lambda), i.e.
        
        y = (sign(x) * abs(x) ** lamda - 1) / lambda 
        
        This follows the generalization in Bicken and Doksum (1981) JASA 76
        and allows x to assume negative values. 
    &quot;&quot;&quot;

    def __init__(self):
        self.n_params = 1
    
    def _get_params(self, param):
        
        return np.exp(param)

<div class="viewcode-block" id="WarpBoxCox.f"><a class="viewcode-back" href="../modindex.html#utils.WarpBoxCox.f">[docs]</a>    def f(self, x, params):
        lam = self._get_params(params)
        
        if lam == 0:
            y = np.log(x)
        else:
            y = (np.sign(x) * np.abs(x) ** lam - 1) / lam 
        return y</div>
    
<div class="viewcode-block" id="WarpBoxCox.invf"><a class="viewcode-back" href="../modindex.html#utils.WarpBoxCox.invf">[docs]</a>    def invf(self, y, params):
        lam = self._get_params(params)
     
        if lam == 0:
            x = np.exp(y)
        else:
            x = np.sign(lam * y + 1) * np.abs(lam * y + 1) ** (1 / lam)

        return x</div>

<div class="viewcode-block" id="WarpBoxCox.df"><a class="viewcode-back" href="../modindex.html#utils.WarpBoxCox.df">[docs]</a>    def df(self, x, params):
        lam = self._get_params(params)
        
        dx = np.abs(x) ** (lam - 1)
        
        return dx</div></div>

<div class="viewcode-block" id="WarpSinArcsinh"><a class="viewcode-back" href="../modindex.html#utils.WarpSinArcsinh">[docs]</a>class WarpSinArcsinh(WarpBase):
    &quot;&quot;&quot; Sin-hyperbolic arcsin warp having two parameters (a, b) and defined by 
    
        y = sinh(b *  arcsinh(x) - a)
    
        see Jones and Pewsey A (2009) Biometrika, 96 (4) (2009)
    &quot;&quot;&quot;

    def __init__(self):
        self.n_params = 2
    
    def _get_params(self, param):
        if len(param) != self.n_params:
            raise(ValueError, 
                  &#39;number of parameters must be &#39; + str(self.n_params))
        return param[0], param[1]

<div class="viewcode-block" id="WarpSinArcsinh.f"><a class="viewcode-back" href="../modindex.html#utils.WarpSinArcsinh.f">[docs]</a>    def f(self, x, params):
        a, b = self._get_params(params)
        
        y = np.sinh(b * np.arcsinh(x) - a)
        return y</div>
    
<div class="viewcode-block" id="WarpSinArcsinh.invf"><a class="viewcode-back" href="../modindex.html#utils.WarpSinArcsinh.invf">[docs]</a>    def invf(self, y, params):
        a, b = self._get_params(params)
     
        x = np.sinh((np.arcsinh(y)+a)/b)
        
        return x</div>

<div class="viewcode-block" id="WarpSinArcsinh.df"><a class="viewcode-back" href="../modindex.html#utils.WarpSinArcsinh.df">[docs]</a>    def df(self, x, params):
        a, b = self._get_params(params)
        
        dx = (b *np.cosh(b * np.arcsinh(x) - a))/np.sqrt(1 + x ** 2)
        
        return dx</div></div>
    
<div class="viewcode-block" id="WarpCompose"><a class="viewcode-back" href="../modindex.html#utils.WarpCompose">[docs]</a>class WarpCompose(WarpBase):
    &quot;&quot;&quot; Composition of warps. These are passed in as an array and
        intialised automatically. For example::

            W = WarpCompose((&#39;WarpBoxCox&#39;, &#39;WarpAffine&#39;))

        where ell_i are lengthscale parameters and sf2 is the signal variance
    &quot;&quot;&quot;

    def __init__(self, warpnames=None):

        if warpnames is None:
            raise ValueError(&quot;A list of warp functions is required&quot;)
        self.warps = []
        self.n_params = 0
        for wname in warpnames:
            warp = eval(wname + &#39;()&#39;)
            self.n_params += warp.get_n_params()
            self.warps.append(warp)

<div class="viewcode-block" id="WarpCompose.f"><a class="viewcode-back" href="../modindex.html#utils.WarpCompose.f">[docs]</a>    def f(self, x, theta):
        theta_offset = 0

        for ci, warp in enumerate(self.warps):
            n_params_c = warp.get_n_params()
            theta_c = [theta[c] for c in
                          range(theta_offset, theta_offset + n_params_c)]
            theta_offset += n_params_c                

            if ci == 0:
                fw = warp.f(x, theta_c)
            else:
                fw = warp.f(fw, theta_c)
        return fw</div>

<div class="viewcode-block" id="WarpCompose.invf"><a class="viewcode-back" href="../modindex.html#utils.WarpCompose.invf">[docs]</a>    def invf(self, x, theta):
        theta_offset = 0
        for ci, warp in enumerate(self.warps):
            n_params_c = warp.get_n_params()
            theta_c = [theta[c] for c in
                       range(theta_offset, theta_offset + n_params_c)]
            theta_offset += n_params_c
            
            if ci == 0:
                finvw = warp.invf(x, theta_c)
            else:
                finvw = warp.invf(finvw, theta_c)
            
        return finvw</div>
    
<div class="viewcode-block" id="WarpCompose.df"><a class="viewcode-back" href="../modindex.html#utils.WarpCompose.df">[docs]</a>    def df(self, x, theta):
        theta_offset = 0
        for ci, warp in enumerate(self.warps):
            n_params_c = warp.get_n_params()

            theta_c = [theta[c] for c in
                       range(theta_offset, theta_offset + n_params_c)]
            theta_offset += n_params_c
            
            if ci == 0:
                dfw = warp.df(x, theta_c)
            else:
                dfw = warp.df(dfw, theta_c)
            
        return dfw</div></div>

# -----------------------
# Functions for inference
# -----------------------

<div class="viewcode-block" id="CustomCV"><a class="viewcode-back" href="../modindex.html#utils.CustomCV">[docs]</a>class CustomCV:
    &quot;&quot;&quot; Custom cross-validation approach. This function does not do much, it
        merely provides a wrapper designed to be compatible with
        scikit-learn (e.g. sklearn.model_selection...)

        :param train: a list of indices of training splits (each itself a list)
        :param test: a list of indices of test splits (each itself a list)

        :returns tr: Indices for training set
        :returns te: Indices for test set &quot;&quot;&quot;

    def __init__(self, train, test, X=None, y=None):
        self.train = train
        self.test = test
        self.n_splits = len(train)
        if X is not None:
            self.N = X.shape[0]
        else:
            self.N = None

<div class="viewcode-block" id="CustomCV.split"><a class="viewcode-back" href="../modindex.html#utils.CustomCV.split">[docs]</a>    def split(self, X, y=None):
        if self.N is None:
            self.N = X.shape[0]

        for i in range(0, self.n_splits):
            tr = self.train[i]
            te = self.test[i]
            yield tr, te</div></div>

# -----------------------
# Functions for inference
# -----------------------

<div class="viewcode-block" id="bashwrap"><a class="viewcode-back" href="../modindex.html#utils.bashwrap">[docs]</a>def bashwrap(processing_dir, python_path, script_command, job_name,
             bash_environment=None):

    &quot;&quot;&quot; This function wraps normative modelling into a bash script to run it
    on a torque cluster system.

    ** Input:
        * processing_dir     -&gt; Full path to the processing dir
        * python_path        -&gt; Full path to the python distribution
        * command to execute -&gt; python command to execute
        * job_name           -&gt; Name for the bash script that is the output of
                                this function
        * covfile_path       -&gt; Full path to a .txt file that contains all
                                covariats (subjects x covariates) for the
                                responsefile
        * respfile_path      -&gt; Full path to a .txt that contains all features
                                (subjects x features)
        * cv_folds           -&gt; Number of cross validations
        * testcovfile_path   -&gt; Full path to a .txt file that contains all
                                covariats (subjects x covariates) for the
                                testresponse file
        * testrespfile_path  -&gt; Full path to a .txt file that contains all
                                test features
        * bash_environment   -&gt; A file containing the necessary commands
                                for your bash environment to work

    ** Output:
        * A bash.sh file containing the commands for normative modelling saved
        to the processing directory

    witten by Thomas Wolfers
    &quot;&quot;&quot;

    # change to processing dir
    os.chdir(processing_dir)
    output_changedir = [&#39;cd &#39; + processing_dir + &#39;\n&#39;]

    # sets bash environment if necessary
    if bash_environment is not None:
        bash_environment = [bash_environment]
        print(&quot;&quot;&quot;Your own environment requires in any case:
              #!/bin/bash\n export and optionally OMP_NUM_THREADS=1\n&quot;&quot;&quot;)
    else:
        bash_lines = &#39;#!/bin/bash\n\n&#39;
        bash_cores = &#39;export OMP_NUM_THREADS=1\n&#39;
        bash_environment = [bash_lines + bash_cores]

    command = [python_path + &#39; &#39; + script_command + &#39;\n&#39;]
    
    # writes bash file into processing dir
    bash_file_name = os.path.join(processing_dir, job_name + &#39;.sh&#39;)
    with open(bash_file_name, &#39;w&#39;) as bash_file:
        bash_file.writelines(bash_environment + output_changedir + command)

    # changes permissoins for bash.sh file
    os.chmod(bash_file_name, 0o700)
    
    return bash_file_name</div>

<div class="viewcode-block" id="qsub"><a class="viewcode-back" href="../modindex.html#utils.qsub">[docs]</a>def qsub(job_path, memory, duration, logdir=None):
    &quot;&quot;&quot;
    This function submits a job.sh scipt to the torque custer using the qsub
    command.

    ** Input:
        * job_path      -&gt; Full path to the job.sh file
        * memory        -&gt; Memory requirements written as string for example
                           4gb or 500mb
        * duration       -&gt; The approximate duration of the job, a string with
                           HH:MM:SS for example 01:01:01

    ** Output:
        * Submission of the job to the (torque) cluster

    witten by Thomas Wolfers
    &quot;&quot;&quot;
    if logdir is None:
        logdir = os.path.expanduser(&#39;~&#39;)

    # created qsub command
    qsub_call = [&#39;echo &#39; + job_path + &#39; | qsub -N &#39; + job_path + &#39; -l &#39; +
                 &#39;mem=&#39; + memory + &#39;,walltime=&#39; + duration + 
                 &#39; -e &#39; + logdir + &#39; -o &#39; + logdir]

    # submits job to cluster
    call(qsub_call, shell=True)</div>
    
<div class="viewcode-block" id="extreme_value_prob_fit"><a class="viewcode-back" href="../modindex.html#utils.extreme_value_prob_fit">[docs]</a>def extreme_value_prob_fit(NPM, perc):
    n = NPM.shape[0]
    t = NPM.shape[1]
    n_perc = int(round(t * perc))
    m = np.zeros(n)
    for i in range(n):
        temp =  np.abs(NPM[i, :])
        temp = np.sort(temp)
        temp = temp[t - n_perc:]
        temp = temp[0:int(np.floor(0.90*temp.shape[0]))]
        m[i] = np.mean(temp)
    params = genextreme.fit(m)
    return params</div>
    
<div class="viewcode-block" id="extreme_value_prob"><a class="viewcode-back" href="../modindex.html#utils.extreme_value_prob">[docs]</a>def extreme_value_prob(params, NPM, perc):
    n = NPM.shape[0]
    t = NPM.shape[1]
    n_perc = int(round(t * perc))
    m = np.zeros(n)
    for i in range(n):
        temp =  np.abs(NPM[i, :])
        temp = np.sort(temp)
        temp = temp[t - n_perc:]
        temp = temp[0:int(np.floor(0.90*temp.shape[0]))]
        m[i] = np.mean(temp)
        probs = genextreme.cdf(m,*params)
    return probs</div>

<div class="viewcode-block" id="ravel_2D"><a class="viewcode-back" href="../modindex.html#utils.ravel_2D">[docs]</a>def ravel_2D(a):
    s = a.shape
    return np.reshape(a,[s[0], np.prod(s[1:])]) </div>

<div class="viewcode-block" id="unravel_2D"><a class="viewcode-back" href="../modindex.html#utils.unravel_2D">[docs]</a>def unravel_2D(a, s):
    return np.reshape(a,s)</div>

<div class="viewcode-block" id="threshold_NPM"><a class="viewcode-back" href="../modindex.html#utils.threshold_NPM">[docs]</a>def threshold_NPM(NPMs, fdr_thr=0.05, npm_thr=0.1):
    &quot;&quot;&quot; Compute voxels with significant NPMs. &quot;&quot;&quot;
    p_values = stats.norm.cdf(-np.abs(NPMs))
    results = np.zeros(NPMs.shape) 
    masks = np.full(NPMs.shape, False, dtype=bool)
    for i in range(p_values.shape[0]): 
        masks[i,:] = FDR(p_values[i,:], fdr_thr)
        results[i,] = NPMs[i,:] * masks[i,:].astype(np.int)
    m = np.sum(masks,axis=0)/masks.shape[0] &gt; npm_thr
    #m = np.any(masks,axis=0)
    return results, masks, m</div>
    
<div class="viewcode-block" id="FDR"><a class="viewcode-back" href="../modindex.html#utils.FDR">[docs]</a>def FDR(p_values, alpha):
    &quot;&quot;&quot; Compute the false discovery rate in all voxels for a subject. &quot;&quot;&quot;
    dim = np.shape(p_values)
    p_values = np.reshape(p_values,[np.prod(dim),])
    sorted_p_values = np.sort(p_values)
    sorted_p_values_idx = np.argsort(p_values);  
    testNum = len(p_values)
    thresh = ((np.array(range(testNum)) + 1)/np.float(testNum))  * alpha
    h = sorted_p_values &lt;= thresh
    unsort = np.argsort(sorted_p_values_idx)
    h = h[unsort]
    h = np.reshape(h, dim)
    return h</div>


<div class="viewcode-block" id="calibration_error"><a class="viewcode-back" href="../modindex.html#utils.calibration_error">[docs]</a>def calibration_error(Y,m,s,cal_levels):
    ce = 0
    for cl in cal_levels:
        z = np.abs(norm.ppf((1-cl)/2))
        ub = m + z * s
        lb = m - z * s
        ce = ce + np.abs(cl - np.sum(np.logical_and(Y&gt;=lb,Y&lt;=ub))/Y.shape[0])
    return ce</div>


<div class="viewcode-block" id="simulate_data"><a class="viewcode-back" href="../modindex.html#utils.simulate_data">[docs]</a>def simulate_data(method=&#39;linear&#39;, n_samples=100, n_features=1, n_grps=1, 
                  working_dir=None, plot=False, random_state=None, noise=None):
    &quot;&quot;&quot;
    This function simulates linear synthetic data for testing pcntoolkit methods.
    
    - Inputs:
        
        - method: simulate &#39;linear&#39; or &#39;non-linear&#39; function.
        
        - n_samples: number of samples in each group of the training and test sets. 
        If it is an int then the same sample number will be used for all groups. 
        It can be also a list of size of n_grps that decides the number of samples 
        in each group (default=100).
        
        - n_features: A positive integer that decides the number of features 
        (default=1).
        
        - n_grps: A positive integer that decides the number of groups in data
        (default=1).
        
        - working_dir: Directory to save data (default=None). 
        
        - plot: Boolean to plot the simulated training data (default=False).
        
        - random_state: random state for generating random numbers (Default=None).
        
        - noise: Type of added noise to the data. The options are &#39;gaussian&#39;, 
        &#39;exponential&#39;, and &#39;hetero_gaussian&#39; (The defauls is None.). 
    
    - Outputs:
        
        - X_train, Y_train, grp_id_train, X_test, Y_test, grp_id_test, coef
    
    &quot;&quot;&quot;
    
    if isinstance(n_samples, int):
        n_samples = [n_samples for i in range(n_grps)]
        
    X_train, Y_train, X_test, Y_test = [], [], [], []
    grp_id_train, grp_id_test = [], []
    coef = []
    for i in range(n_grps):
        bias = np.random.randint(-10, high=10)
        
        if method == &#39;linear&#39;:
            X_temp, Y_temp, coef_temp = make_regression(n_samples=n_samples[i]*2, 
                                    n_features=n_features, n_targets=1, 
                                    noise=10 * np.random.rand(), bias=bias, 
                                    n_informative=1, coef=True, 
                                    random_state=random_state)
        elif method == &#39;non-linear&#39;:
            X_temp = np.random.randint(-2,6,[2*n_samples[i], n_features]) \
                    + np.random.randn(2*n_samples[i], n_features)
            Y_temp = X_temp[:,0] * 20 * np.random.rand() + np.random.randint(10,100) \
                        * np.sin(2 * np.random.rand() + 2 * np.pi /5 * X_temp[:,0]) 
            coef_temp = 0
        elif method == &#39;combined&#39;:
            X_temp = np.random.randint(-2,6,[2*n_samples[i], n_features]) \
                    + np.random.randn(2*n_samples[i], n_features)
            Y_temp = (X_temp[:,0]**3) * np.random.uniform(0, 0.5) \
                    + X_temp[:,0] * 20 * np.random.rand() \
                    + np.random.randint(10, 100)
            coef_temp = 0
        else:
            raise ValueError(&quot;Unknow method. Please specify valid method among \
                             &#39;linear&#39; or  &#39;non-linear&#39;.&quot;)
        coef.append(coef_temp/100)
        X_train.append(X_temp[:X_temp.shape[0]//2])
        Y_train.append(Y_temp[:X_temp.shape[0]//2]/100)
        X_test.append(X_temp[X_temp.shape[0]//2:])
        Y_test.append(Y_temp[X_temp.shape[0]//2:]/100)
        grp_id = np.repeat(i, X_temp.shape[0])
        grp_id_train.append(grp_id[:X_temp.shape[0]//2])
        grp_id_test.append(grp_id[X_temp.shape[0]//2:])
        
        if noise == &#39;hetero_gaussian&#39;:
            t = np.random.randint(5,10)
            Y_train[i] = Y_train[i] + np.random.randn(Y_train[i].shape[0]) / t \
                        * np.log(1 + np.exp(X_train[i][:,0]))
            Y_test[i] = Y_test[i] + np.random.randn(Y_test[i].shape[0]) / t \
                        * np.log(1 + np.exp(X_test[i][:,0]))
        elif noise == &#39;gaussian&#39;:
            t = np.random.randint(3,10)
            Y_train[i] = Y_train[i] + np.random.randn(Y_train[i].shape[0])/t
            Y_test[i] = Y_test[i] + np.random.randn(Y_test[i].shape[0])/t
        elif noise == &#39;exponential&#39;:
            t = np.random.randint(1,3)
            Y_train[i] = Y_train[i] + np.random.exponential(1, Y_train[i].shape[0]) / t
            Y_test[i] = Y_test[i] + np.random.exponential(1, Y_test[i].shape[0]) / t
        elif noise == &#39;hetero_gaussian_smaller&#39;:
            t = np.random.randint(5,10)
            Y_train[i] = Y_train[i] + np.random.randn(Y_train[i].shape[0]) / t \
                        * np.log(1 + np.exp(0.3 * X_train[i][:,0]))
            Y_test[i] = Y_test[i] + np.random.randn(Y_test[i].shape[0]) / t \
                        * np.log(1 + np.exp(0.3 * X_test[i][:,0]))
    X_train = np.vstack(X_train)
    X_test = np.vstack(X_test)
    Y_train = np.concatenate(Y_train)
    Y_test = np.concatenate(Y_test)
    grp_id_train = np.expand_dims(np.concatenate(grp_id_train), axis=1)
    grp_id_test = np.expand_dims(np.concatenate(grp_id_test), axis=1)
    
    for i in range(n_features):
        plt.figure()
        for j in range(n_grps):
            plt.scatter(X_train[grp_id_train[:,0]==j,i],
                Y_train[grp_id_train[:,0]==j,], label=&#39;Group &#39; + str(j))
        plt.xlabel(&#39;X&#39; + str(i))
        plt.ylabel(&#39;Y&#39;)
        plt.legend()
        
    if working_dir is not None:
        if not os.path.isdir(working_dir):
            os.mkdir(working_dir)
        with open(os.path.join(working_dir ,&#39;trbefile.pkl&#39;), &#39;wb&#39;) as file:
            pickle.dump(pd.DataFrame(grp_id_train),file)
        with open(os.path.join(working_dir ,&#39;tsbefile.pkl&#39;), &#39;wb&#39;) as file:
            pickle.dump(pd.DataFrame(grp_id_test),file)
        with open(os.path.join(working_dir ,&#39;X_train.pkl&#39;), &#39;wb&#39;) as file:
            pickle.dump(pd.DataFrame(X_train),file)
        with open(os.path.join(working_dir ,&#39;X_test.pkl&#39;), &#39;wb&#39;) as file:
            pickle.dump(pd.DataFrame(X_test),file)
        with open(os.path.join(working_dir ,&#39;Y_train.pkl&#39;), &#39;wb&#39;) as file:
            pickle.dump(pd.DataFrame(Y_train),file)
        with open(os.path.join(working_dir ,&#39;Y_test.pkl&#39;), &#39;wb&#39;) as file:
            pickle.dump(pd.DataFrame(Y_test),file)
        
    return X_train, Y_train, grp_id_train, X_test, Y_test, grp_id_test, coef</div>


<div class="viewcode-block" id="divergence_plot"><a class="viewcode-back" href="../modindex.html#utils.divergence_plot">[docs]</a>def divergence_plot(nm, ylim=None):
    
    if nm.hbr.configs[&#39;n_chains&#39;] &gt; 1 and nm.hbr.model_type != &#39;nn&#39;:
        a = pm.summary(nm.hbr.trace).round(2)
        plt.figure()
        plt.hist(a[&#39;r_hat&#39;],10)
        plt.title(&#39;Gelman-Rubin diagnostic for divergence&#39;)

    divergent = nm.hbr.trace[&#39;diverging&#39;]
        
    tracedf = pm.trace_to_dataframe(nm.hbr.trace)
    
    _, ax = plt.subplots(2, 1, figsize=(15, 4), sharex=True, sharey=True)
    ax[0].plot(tracedf.values[divergent == 0].T, color=&#39;k&#39;, alpha=.05)
    ax[0].set_title(&#39;No Divergences&#39;, fontsize=10)
    ax[1].plot(tracedf.values[divergent == 1].T, color=&#39;C2&#39;, lw=.5, alpha=.5)
    ax[1].set_title(&#39;Divergences&#39;, fontsize=10)
    plt.ylim(ylim)
    plt.xticks(range(tracedf.shape[1]), list(tracedf.columns))
    plt.xticks(rotation=90, fontsize=7)
    plt.tight_layout()
    plt.show()</div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Andre F. Marquand

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>