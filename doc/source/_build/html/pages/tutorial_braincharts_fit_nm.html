<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Braincharts: fit model &mdash; Predictive Clinical Neuroscience Toolkit 0.20 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/pages/css/pcntoolkit_tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/pages/css/pcntoolkit.css" type="text/css" />
      <link rel="stylesheet" href="../_static/pages/css/pcntoolkit_nomaxwidth.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Braincharts: apply (transfer to new data)" href="tutorial_braincharts_apply_nm.html" />
    <link rel="prev" title="Hierarchical Bayesian Regression" href="tutorial_HBR.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/pcn-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="pcntoolkit_background.html">PCNtoolkit Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="pcntoolkit_background.html#intro-to-normative-modelling">Intro to normative modelling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function &amp; Class Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modindex.html">Module Index</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Current Events</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="updates.html">Updates</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="tutorial_CPC2020.html">Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_ROIcorticalthickness.html">Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_HBR.html">Hierarchical Bayesian Regression</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Braincharts: fit model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#configure-which-models-to-fit">Configure which models to fit</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configure-model-parameters">Configure model parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fit-the-models">Fit the models</a></li>
<li class="toctree-l2"><a class="reference internal" href="#compute-error-metrics">Compute error metrics</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_braincharts_apply_nm.html">Braincharts: apply (transfer to new data)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Useful Stuff</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="FAQs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="citing.html">How to cite PCNtoolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgements.html">Acknowledgements</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Predictive Clinical Neuroscience Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Braincharts: fit model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/pages/tutorial_braincharts_fit_nm.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="braincharts-fit-model">
<h1>Braincharts: fit model<a class="headerlink" href="#braincharts-fit-model" title="Permalink to this headline"></a></h1>
<p>This notebook provides a complete walkthrough for an analysis of
normative modelling in a large sample as described in the accompanying
paper. Note that this script is provided principally for completeness
(e.g. to assist in fitting normative models to new datasets). All
pre-estimated normative models are already provided.</p>
<blockquote>
<div><p><a class="reference external" href="https://colab.research.google.com/github/predictive-clinical-neuroscience/braincharts/blob/master/scripts/fit_normative_models.ipynb">Open/Run in Google Colab</a></p>
</div></blockquote>
<p>First, if necessary, we install PCNtoolkit (note: this tutorial requires
at least version 0.20)</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pip install pcntoolkit==0.20
</pre></div>
</div>
<p>Then we import the required libraries</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import numpy as np
import pandas as pd
import pickle
from matplotlib import pyplot as plt
import seaborn as sns

from pcntoolkit.normative import estimate, predict, evaluate
from pcntoolkit.util.utils import compute_MSLL, create_design_matrix
from nm_utils import calibration_descriptives, remove_bad_subjects, load_2d
</pre></div>
</div>
<p>Now, we configure the locations in which the data are stored. You will
need to configure this for your specific installation</p>
<p><strong>Notes:</strong> - The data are assumed to be in CSV format and will be loaded
as pandas dataframes - Generally the raw data will be in a different
location to the analysis - The data can have arbitrary columns but some
are required by the script, i.e. ‘age’, ‘sex’ and ‘site’, plus the
phenotypes you wish to estimate (see below)</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># where the raw data are stored
data_dir = &#39;&lt;path-to-your&gt;/data&#39;

# where the analysis takes place
root_dir = &#39;&lt;path-to-your&gt;/braincharts&#39;
out_dir = os.path.join(root_dir,&#39;models&#39;,&#39;test&#39;)

# create the output directory if it does not already exist
os.makedirs(out_dir, exist_ok=True)
</pre></div>
</div>
<p>Now we load the data.</p>
<p>We will load one pandas dataframe for the training set and one dataframe
for the test set. We will also filter out low quality scans on the basis
of the Freesurfer <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/EulerNumber">Euler
Characteristic</a>
(EC). This is a proxy for scan quality and is described in the
publications below. Note that this requires the column ‘avg_en’ in the
pandas dataframe, which is simply the average EC of left and right
hemisphere.</p>
<p>We also configrure a list of site ids</p>
<p><strong>References</strong> - <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2021.05.28.446120v1.abstract">Kia et al
2021</a>
- <a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S1053811917310832?via%3Dihub">Rosen et al
2018</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>df_tr = pd.read_csv(os.path.join(data_dir,&#39;lifespan_big_controls_tr_mqc.csv&#39;), index_col=0)
df_te = pd.read_csv(os.path.join(data_dir,&#39;lifespan_big_controls_te_mqc.csv&#39;), index_col=0)

# remove some bad subjects
df_tr, bad_sub = remove_bad_subjects(df_tr, df_tr)
df_te, bad_sub = remove_bad_subjects(df_te, df_te)

# extract a list of unique site ids from the training set
site_ids =  sorted(set(df_tr[&#39;site&#39;].to_list()))
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>362 subjects are removed!
356 subjects are removed!
</pre></div>
</div>
<div class="section" id="configure-which-models-to-fit">
<h2>Configure which models to fit<a class="headerlink" href="#configure-which-models-to-fit" title="Permalink to this headline"></a></h2>
<p>Next, we load the image derived phenotypes (IDPs) which we will process
in this analysis. This is effectively just a list of columns in your
dataframe. Here we estimate normative models for the left hemisphere,
right hemisphere and cortical structures.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># load the idps to process
with open(os.path.join(root_dir,&#39;docs&#39;,&#39;phenotypes_lh.txt&#39;)) as f:
    idp_ids_lh = f.read().splitlines()
with open(os.path.join(root_dir,&#39;docs&#39;,&#39;phenotypes_rh.txt&#39;)) as f:
    idp_ids_rh = f.read().splitlines()
with open(os.path.join(root_dir,&#39;docs&#39;,&#39;phenotypes_sc.txt&#39;)) as f:
    idp_ids_sc = f.read().splitlines()

# we choose here to process all idps
idp_ids = idp_ids_lh + idp_ids_rh + idp_ids_sc

# we could also just specify a list of IDPs
#idp_ids = [&#39;lh_MeanThickness_thickness&#39;, &#39;rh_MeanThickness_thickness&#39;]
</pre></div>
</div>
</div>
<div class="section" id="configure-model-parameters">
<h2>Configure model parameters<a class="headerlink" href="#configure-model-parameters" title="Permalink to this headline"></a></h2>
<p>Now, we configure some parameters for the regression model we use to fit
the normative model. Here we will use a ‘warped’ Bayesian linear
regression model. To model non-Gaussianity, we select a sin arcsinh warp
and to model non-linearity, we stick with the default value for the
basis expansion (a cubic b-spline basis set with 5 knot points). Since
we are sticking with the default value, we do not need to specify any
parameters for this, but we do need to specify the limits. We choose to
pad the input by a few years either side of the input range. We will
also set a couple of options that control the estimation of the model</p>
<p>For further details about the likelihood warping approach, see <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2021.04.05.438429v1">Fraza et
al
2021</a>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># which data columns do we wish to use as covariates?
cols_cov = [&#39;age&#39;,&#39;sex&#39;]

# which warping function to use? We can set this to None in order to fit a vanilla Gaussian noise model
warp =  &#39;WarpSinArcsinh&#39;

# limits for cubic B-spline basis
xmin = -5
xmax = 110

# Do we want to force the model to be refit every time?
force_refit = True

# Absolute Z treshold above which a sample is considered to be an outlier (without fitting any model)
outlier_thresh = 7
</pre></div>
</div>
</div>
<div class="section" id="fit-the-models">
<h2>Fit the models<a class="headerlink" href="#fit-the-models" title="Permalink to this headline"></a></h2>
<p>Now we fit the models. This involves looping over the IDPs we have
selected. We will use a module from PCNtoolkit to set up the design
matrices, containing the covariates, fixed effects for site and
nonlinear basis expansion.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for idp_num, idp in enumerate(idp_ids):
    print(&#39;Running IDP&#39;, idp_num, idp, &#39;:&#39;)

    # set output dir
    idp_dir = os.path.join(out_dir, idp)
    os.makedirs(os.path.join(idp_dir), exist_ok=True)
    os.chdir(idp_dir)

    # extract the response variables for training and test set
    y_tr = df_tr[idp].to_numpy()
    y_te = df_te[idp].to_numpy()

    # remove gross outliers and implausible values
    yz_tr = (y_tr - np.mean(y_tr)) / np.std(y_tr)
    yz_te = (y_te - np.mean(y_te)) / np.std(y_te)
    nz_tr = np.bitwise_and(np.abs(yz_tr) &lt; outlier_thresh, y_tr &gt; 0)
    nz_te = np.bitwise_and(np.abs(yz_te) &lt; outlier_thresh, y_te &gt; 0)
    y_tr = y_tr[nz_tr]
    y_te = y_te[nz_te]

    # write out the response variables for training and test
    resp_file_tr = os.path.join(idp_dir, &#39;resp_tr.txt&#39;)
    resp_file_te = os.path.join(idp_dir, &#39;resp_te.txt&#39;)
    np.savetxt(resp_file_tr, y_tr)
    np.savetxt(resp_file_te, y_te)

    # configure the design matrix
    X_tr = create_design_matrix(df_tr[cols_cov].loc[nz_tr],
                                site_ids = df_tr[&#39;site&#39;].loc[nz_tr],
                                basis = &#39;bspline&#39;,
                                xmin = xmin,
                                xmax = xmax)
    X_te = create_design_matrix(df_te[cols_cov].loc[nz_te],
                                site_ids = df_te[&#39;site&#39;].loc[nz_te],
                                all_sites=site_ids,
                                basis = &#39;bspline&#39;,
                                xmin = xmin,
                                xmax = xmax)

    # configure and save the covariates
    cov_file_tr = os.path.join(idp_dir, &#39;cov_bspline_tr.txt&#39;)
    cov_file_te = os.path.join(idp_dir, &#39;cov_bspline_te.txt&#39;)
    np.savetxt(cov_file_tr, X_tr)
    np.savetxt(cov_file_te, X_te)

    if not force_refit and os.path.exists(os.path.join(idp_dir, &#39;Models&#39;, &#39;NM_0_0_estimate.pkl&#39;)):
        print(&#39;Making predictions using a pre-existing model...&#39;)
        suffix = &#39;predict&#39;

        # Make prdictsion with test data
        predict(cov_file_te,
                alg=&#39;blr&#39;,
                respfile=resp_file_te,
                model_path=os.path.join(idp_dir,&#39;Models&#39;),
                outputsuffix=suffix)
    else:
        print(&#39;Estimating the normative model...&#39;)
        estimate(cov_file_tr, resp_file_tr, testresp=resp_file_te,
                 testcov=cov_file_te, alg=&#39;blr&#39;, optimizer = &#39;l-bfgs-b&#39;,
                 savemodel=True, warp=warp, warp_reparam=True)
        suffix = &#39;estimate&#39;
</pre></div>
</div>
</div>
<div class="section" id="compute-error-metrics">
<h2>Compute error metrics<a class="headerlink" href="#compute-error-metrics" title="Permalink to this headline"></a></h2>
<p>In this section we compute the following error metrics for all IDPs (all
evaluated on the test set):</p>
<ul class="simple">
<li><p>Negative log likelihood (NLL)</p></li>
<li><p>Explained variance (EV)</p></li>
<li><p>Mean standardized log loss (MSLL)</p></li>
<li><p>Bayesian information Criteria (BIC)</p></li>
<li><p>Skew and Kurtosis of the Z-distribution</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialise dataframe we will use to store quantitative metrics
blr_metrics = pd.DataFrame(columns = [&#39;eid&#39;, &#39;NLL&#39;, &#39;EV&#39;, &#39;MSLL&#39;, &#39;BIC&#39;,&#39;Skew&#39;,&#39;Kurtosis&#39;])

for idp_num, idp in enumerate(idp_ids):
    idp_dir = os.path.join(out_dir, idp)

    # load the predictions and true data. We use a custom function that ensures 2d arrays
    # equivalent to: y = np.loadtxt(filename); y = y[:, np.newaxis]
    yhat_te = load_2d(os.path.join(idp_dir, &#39;yhat_&#39; + suffix + &#39;.txt&#39;))
    s2_te = load_2d(os.path.join(idp_dir, &#39;ys2_&#39; + suffix + &#39;.txt&#39;))
    y_te = load_2d(os.path.join(idp_dir, &#39;resp_te.txt&#39;))

    with open(os.path.join(idp_dir,&#39;Models&#39;, &#39;NM_0_0_estimate.pkl&#39;), &#39;rb&#39;) as handle:
        nm = pickle.load(handle)

    # compute error metrics
    if warp is None:
        metrics = evaluate(y_te, yhat_te)

        # compute MSLL manually as a sanity check
        y_tr_mean = np.array( [[np.mean(y_tr)]] )
        y_tr_var = np.array( [[np.var(y_tr)]] )
        MSLL = compute_MSLL(y_te, yhat_te, s2_te, y_tr_mean, y_tr_var)
    else:
        warp_param = nm.blr.hyp[1:nm.blr.warp.get_n_params()+1]
        W = nm.blr.warp

        # warp predictions
        med_te = W.warp_predictions(np.squeeze(yhat_te), np.squeeze(s2_te), warp_param)[0]
        med_te = med_te[:, np.newaxis]

        # evaluation metrics
        metrics = evaluate(y_te, med_te)

        # compute MSLL manually
        y_te_w = W.f(y_te, warp_param)
        y_tr_w = W.f(y_tr, warp_param)
        y_tr_mean = np.array( [[np.mean(y_tr_w)]] )
        y_tr_var = np.array( [[np.var(y_tr_w)]] )
        MSLL = compute_MSLL(y_te_w, yhat_te, s2_te, y_tr_mean, y_tr_var)

    Z = np.loadtxt(os.path.join(idp_dir, &#39;Z_&#39; + suffix + &#39;.txt&#39;))
    [skew, sdskew, kurtosis, sdkurtosis, semean, sesd] = calibration_descriptives(Z)

    BIC = len(nm.blr.hyp) * np.log(y_tr.shape[0]) + 2 * nm.neg_log_lik

    blr_metrics.loc[len(blr_metrics)] = [idp, nm.neg_log_lik, metrics[&#39;EXPV&#39;][0],
                                         MSLL[0], BIC, skew, kurtosis]

display(blr_metrics)

blr_metrics.to_pickle(os.path.join(out_dir,&#39;blr_metrics.pkl&#39;))
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>eid</th>
      <th>NLL</th>
      <th>EV</th>
      <th>MSLL</th>
      <th>BIC</th>
      <th>Skew</th>
      <th>Kurtosis</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>lh_G&amp;S_frontomargin_thickness</td>
      <td>-3808.584381</td>
      <td>0.314419</td>
      <td>-35.106351</td>
      <td>-7579.659922</td>
      <td>0.252934</td>
      <td>1.087225</td>
    </tr>
    <tr>
      <th>1</th>
      <td>lh_G&amp;S_occipital_inf_thickness</td>
      <td>-3468.296931</td>
      <td>0.230447</td>
      <td>-35.096839</td>
      <td>-6899.085023</td>
      <td>0.030063</td>
      <td>0.430915</td>
    </tr>
    <tr>
      <th>2</th>
      <td>lh_G&amp;S_paracentral_thickness</td>
      <td>-2977.898155</td>
      <td>0.337686</td>
      <td>-35.035891</td>
      <td>-5918.287470</td>
      <td>-0.001040</td>
      <td>0.755307</td>
    </tr>
    <tr>
      <th>3</th>
      <td>lh_G&amp;S_subcentral_thickness</td>
      <td>-3471.667467</td>
      <td>0.332549</td>
      <td>-34.990710</td>
      <td>-6905.826095</td>
      <td>0.072970</td>
      <td>0.560048</td>
    </tr>
    <tr>
      <th>4</th>
      <td>lh_G&amp;S_transv_frontopol_thickness</td>
      <td>-1565.916398</td>
      <td>0.358683</td>
      <td>-34.900294</td>
      <td>-3094.323956</td>
      <td>0.270502</td>
      <td>1.269709</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>183</th>
      <td>TotalGrayVol</td>
      <td>146369.741818</td>
      <td>0.615736</td>
      <td>-3.067824</td>
      <td>292776.992475</td>
      <td>-0.490089</td>
      <td>3.996252</td>
    </tr>
    <tr>
      <th>184</th>
      <td>SupraTentorialVol</td>
      <td>152270.636605</td>
      <td>0.345575</td>
      <td>-1.442556</td>
      <td>304578.782049</td>
      <td>-0.302217</td>
      <td>2.920578</td>
    </tr>
    <tr>
      <th>185</th>
      <td>SupraTentorialVolNotVent</td>
      <td>162984.467798</td>
      <td>0.347517</td>
      <td>-1.014633</td>
      <td>326006.444436</td>
      <td>-5.035215</td>
      <td>63.806125</td>
    </tr>
    <tr>
      <th>186</th>
      <td>avg_thickness</td>
      <td>-10627.007679</td>
      <td>0.581347</td>
      <td>-36.109891</td>
      <td>-21216.506518</td>
      <td>-0.343804</td>
      <td>1.197945</td>
    </tr>
    <tr>
      <th>187</th>
      <td>EstimatedTotalIntraCranialVol</td>
      <td>168794.712119</td>
      <td>0.253537</td>
      <td>-0.262857</td>
      <td>337626.933077</td>
      <td>-5.151926</td>
      <td>66.531844</td>
    </tr>
  </tbody>
</table>
<p>188 rows × 7 columns</p>
</div><div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>blr_metrics.to_csv(os.path.join(out_dir,&#39;blr_metrics.csv&#39;))
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tutorial_HBR.html" class="btn btn-neutral float-left" title="Hierarchical Bayesian Regression" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tutorial_braincharts_apply_nm.html" class="btn btn-neutral float-right" title="Braincharts: apply (transfer to new data)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Andre F. Marquand.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>