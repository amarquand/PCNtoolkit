<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>rfa &mdash; Predictive Clinical Neuroscience Toolkit 0.20 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/pages/css/pcntoolkit_tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/pages/css/pcntoolkit.css" type="text/css" />
      <link rel="stylesheet" href="../_static/pages/css/pcntoolkit_nomaxwidth.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/tabs.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/pcn-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/installation.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/pcntoolkit_background.html">PCNtoolkit Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/pcntoolkit_background.html#intro-to-normative-modelling">Intro to normative modelling</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Function &amp; Class Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modindex.html">Module Index</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Current Events</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/updates.html">Updates</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_CPC2020.html">Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_ROIcorticalthickness.html">Bayesian Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_HBR.html">Hierarchical Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_braincharts_fit_nm.html">Braincharts: fit model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/tutorial_braincharts_apply_nm.html">Braincharts: apply (transfer to new data)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other Useful Stuff</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pages/FAQs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/citing.html">How to cite PCNtoolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/acknowledgements.html">Acknowledgements</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Predictive Clinical Neuroscience Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Module code</a> &raquo;</li>
      <li>rfa</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for rfa</h1><div class="highlight"><pre>
<span></span>from __future__ import print_function
from __future__ import division

import numpy as np
import torch

<div class="viewcode-block" id="GPRRFA"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA">[docs]</a>class GPRRFA:
    &quot;&quot;&quot;Random Feature Approximation for Gaussian Process Regression

    Estimation and prediction of Bayesian linear regression models

    Basic usage::

        R = GPRRFA()
        hyp = R.estimate(hyp0, X, y)
        ys,s2 = R.predict(hyp, X, y, Xs)

    where the variables are

    :param hyp: vector of hyperparmaters.
    :param X: N x D data array
    :param y: 1D Array of targets (length N)
    :param Xs: Nte x D array of test cases
    :param hyp0: starting estimates for hyperparameter optimisation

    :returns: * ys - predictive mean
              * s2 - predictive variance

    The hyperparameters are::

        hyp = [ log(sn), log(ell), log(sf) ]  # hyp is a numpy array

    where sn^2 is the noise variance, ell are lengthscale parameters and 
    sf^2 is the signal variance. This provides an approximation to the
    covariance function::
        
        k(x,z) = x&#39;*z + sn2*exp(0.5*(x-z)&#39;*Lambda*(x-z))
    
    where Lambda = diag((ell_1^2, ... ell_D^2))

    Written by A. Marquand
    &quot;&quot;&quot;

    def __init__(self, hyp=None, X=None, y=None, n_feat=None,
                 n_iter=100, tol=1e-3, verbose=False):

        self.hyp = np.nan
        self.nlZ = np.nan
        self.tol = tol          # not used at present
        self.Nf = n_feat
        self.n_iter = n_iter
        self.verbose = verbose
        self._n_restarts = 5

        if (hyp is not None) and (X is not None) and (y is not None):
            self.post(hyp, X, y)

    def _numpy2torch(self, X, y=None, hyp=None):

        if type(X) is torch.Tensor:
           pass
        elif type(X) is np.ndarray:
           X = torch.from_numpy(X)
        else:
           raise(ValueError, &#39;Unknown data type (X)&#39;)
        X = X.double()
        
        if y is not None:
            if type(y) is torch.Tensor:
                pass
            elif type(y) is np.ndarray:
                y = torch.from_numpy(y)
            else:
                raise(ValueError, &#39;Unknown data type (y)&#39;)
            
            if len(y.shape) == 1:
                y.resize_(y.shape[0],1)
            y = y.double()
        
        if hyp is not None:
            if type(hyp) is torch.Tensor:
                pass
            else:
                hyp = torch.tensor(hyp, requires_grad=True)
        
        return X, y, hyp
    
<div class="viewcode-block" id="GPRRFA.get_n_params"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA.get_n_params">[docs]</a>    def get_n_params(self, X):
        
        return X.shape[1] + 2</div>
        
<div class="viewcode-block" id="GPRRFA.post"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA.post">[docs]</a>    def post(self, hyp, X, y):
        &quot;&quot;&quot; Generic function to compute posterior distribution.

            This function will save the posterior mean and precision matrix as
            self.m and self.A and will also update internal parameters (e.g.
            N, D and the prior covariance (Sigma) and precision (iSigma).
        &quot;&quot;&quot;
     
        # make sure all variables are the right type
        X, y, hyp = self._numpy2torch(X, y, hyp)
        
        self.N, self.Dx = X.shape
        
        # ensure the number of features is specified (use 75% as a default)
        if self.Nf is None:
            self.Nf = int(0.75 * self.N)
        
        self.Omega = torch.zeros((self.Dx, self.Nf), dtype=torch.double)
        for f in range(self.Nf):
            self.Omega[:,f] = torch.exp(hyp[1:-1]) * \
            torch.randn((self.Dx, 1), dtype=torch.double).squeeze()

        XO = torch.mm(X, self.Omega) 
        self.Phi = torch.exp(hyp[-1])/np.sqrt(self.Nf) *  \
                   torch.cat((torch.cos(XO), torch.sin(XO)), 1)
        
        # concatenate linear weights 
        self.Phi = torch.cat((self.Phi, X), 1)
        self.D = self.Phi.shape[1]

        if self.verbose:
            print(&quot;estimating posterior ... | hyp=&quot;, hyp)
        
        self.A = torch.mm(torch.t(self.Phi), self.Phi) / torch.exp(2*hyp[0]) + \
                 torch.eye(self.D, dtype=torch.double)
        self.m = torch.mm(torch.solve(torch.t(self.Phi), self.A)[0], y) / \
                 torch.exp(2*hyp[0])

        # save hyperparameters
        self.hyp = hyp
        
        # update optimizer iteration count
        if hasattr(self,&#39;_iterations&#39;):
            self._iterations += 1</div>

<div class="viewcode-block" id="GPRRFA.loglik"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA.loglik">[docs]</a>    def loglik(self, hyp, X, y):
        &quot;&quot;&quot; Function to compute compute log (marginal) likelihood &quot;&quot;&quot;
        X, y, hyp = self._numpy2torch(X, y, hyp)

        # always recompute the posterior
        self.post(hyp, X, y)

        #logdetA = 2*torch.sum(torch.log(torch.diag(torch.cholesky(self.A))))
        try:
            # compute the log determinants in a numerically stable way
            logdetA = 2*torch.sum(torch.log(torch.diag(torch.cholesky(self.A))))
        except Exception as e:
            print(&quot;Warning: Estimation of posterior distribution failed&quot;)
            print(e)
            #nlZ = torch.tensor(1/np.finfo(float).eps)
            nlZ = torch.tensor(np.nan)
            self._optim_failed = True
            return nlZ
        
        # compute negative marginal log likelihood
        nlZ = -0.5 * (self.N*torch.log(1/torch.exp(2*hyp[0])) - 
                      self.N*np.log(2*np.pi) -
                      torch.mm(torch.t(y - torch.mm(self.Phi,self.m)),
                               (y - torch.mm(self.Phi,self.m))) / 
                      torch.exp(2*hyp[0]) -
                      torch.mm(torch.t(self.m), self.m) - logdetA)

        if self.verbose:
            print(&quot;nlZ= &quot;, nlZ, &quot; | hyp=&quot;, hyp)

        # save marginal likelihood
        self.nlZ = nlZ
        return nlZ</div>

<div class="viewcode-block" id="GPRRFA.dloglik"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA.dloglik">[docs]</a>    def dloglik(self, hyp, X, y):
        &quot;&quot;&quot; Function to compute derivatives &quot;&quot;&quot;

        print(&quot;derivatives not available&quot;)

        return</div>

<div class="viewcode-block" id="GPRRFA.estimate"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA.estimate">[docs]</a>    def estimate(self, hyp0, X, y, optimizer=&#39;lbfgs&#39;):
        &quot;&quot;&quot; Function to estimate the model &quot;&quot;&quot;
        
        if type(hyp0) is torch.Tensor:
            hyp = hyp0
            hyp0.requires_grad_()
        else:
            hyp = torch.tensor(hyp0, requires_grad=True) 
        # save the starting values
        self.hyp0 = hyp
        
        if optimizer.lower() == &#39;lbfgs&#39;:
            opt = torch.optim.LBFGS([hyp])
        else:
            raise(ValueError, &quot;Optimizer &quot; + &quot; not implemented&quot;)
        self._iterations = 0
        
        def closure():
            opt.zero_grad()
            nlZ = self.loglik(hyp, X, y)
            if not torch.isnan(nlZ):
                nlZ.backward()
            return nlZ
        
        for r in range(self._n_restarts):
            self._optim_failed = False
            
            nlZ = opt.step(closure)
            
            if self._optim_failed:
                print(&quot;optimization failed. retrying (&quot;, r+1, &quot;of&quot;, 
                      self._n_restarts,&quot;)&quot;)
                hyp = torch.randn_like(hyp, requires_grad=True)
                self.hyp0 = hyp
            else:
                print(&quot;Optimzation complete after&quot;, self._iterations, 
                      &quot;evaluations. Function value =&quot;, 
                      nlZ.detach().numpy().squeeze())
                break

        return self.hyp.detach().numpy()</div>

<div class="viewcode-block" id="GPRRFA.predict"><a class="viewcode-back" href="../pages/modindex.html#rfa.GPRRFA.predict">[docs]</a>    def predict(self, hyp, X, y, Xs):
        &quot;&quot;&quot; Function to make predictions from the model &quot;&quot;&quot;

        X, y, hyp = self._numpy2torch(X, y, hyp)
        Xs, *_ = self._numpy2torch(Xs)

        if (hyp != self.hyp).all() or not(hasattr(self, &#39;A&#39;)):
            self.post(hyp, X, y)
        
        # generate prediction tensors
        XsO = torch.mm(Xs, self.Omega) 
        Phis = torch.exp(hyp[-1])/np.sqrt(self.Nf) * \
               torch.cat((torch.cos(XsO), torch.sin(XsO)), 1)
        # add linear component
        Phis = torch.cat((Phis, Xs), 1)
        
        ys = torch.mm(Phis, self.m)

        # compute diag(Phis*(Phis&#39;\A)) avoiding computing off-diagonal entries
        s2 = torch.exp(2*hyp[0]) + \
                torch.sum(Phis * torch.t(torch.solve(torch.t(Phis), self.A)[0]), 1)

        # return output as numpy arrays
        return ys.detach().numpy().squeeze(), s2.detach().numpy().squeeze()</div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Andre F. Marquand.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>