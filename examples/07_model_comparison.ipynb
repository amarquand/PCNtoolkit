{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da66d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "\n",
    "import pcntoolkit.util.output\n",
    "from pcntoolkit import (\n",
    "    HBR,\n",
    "    BsplineBasisFunction,\n",
    "    NormalLikelihood,\n",
    "    NormativeModel,\n",
    "    NormData,\n",
    "    load_fcon1000,\n",
    "    make_prior,\n",
    ")\n",
    "from pcntoolkit.util.model_comparison import compare_hbr_models\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Suppress some annoying warnings and logs\n",
    "pymc_logger = logging.getLogger(\"pymc\")\n",
    "\n",
    "pymc_logger.setLevel(logging.WARNING)\n",
    "pymc_logger.propagate = False\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pcntoolkit.util.output.Output.set_show_messages(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3951ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 83743 - 2025-11-20 13:24:56 - Removed 0 NANs\n",
      "Process: 83743 - 2025-11-20 13:24:57 - Dataset \"fcon1000\" created.\n",
      "    - 1078 observations\n",
      "    - 1078 unique subjects\n",
      "    - 1 covariates\n",
      "    - 217 response variables\n",
      "    - 2 batch effects:\n",
      "    \tsex (2)\n",
      "\tsite (23)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Download an example dataset\n",
    "norm_data: NormData = load_fcon1000()\n",
    "\n",
    "# Select only a few features\n",
    "features_to_model = [\n",
    "    \"WM-hypointensities\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    # \"Right-Amygdala\",\n",
    "    # \"CortexVol\",\n",
    "]\n",
    "norm_data = norm_data.sel({\"response_vars\": features_to_model})\n",
    "\n",
    "# Split into train and test sets\n",
    "train, test = norm_data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2768b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = make_prior(\n",
    "    # Mu is linear because we want to allow the mean to vary as a function of the covariates.\n",
    "    linear=True,\n",
    "    # The slope coefficients are assumed to be normally distributed, with a mean of 0 and a standard deviation of 10.\n",
    "    slope=make_prior(dist_name=\"Normal\", dist_params=(0.0, 5.0)),\n",
    "    # The intercept is not random, because we want to compare to a model with random intercept\n",
    "    intercept=make_prior(\n",
    "        dist_name=\"Normal\",\n",
    "        dist_params=(0.0, 2.0),\n",
    "    ),\n",
    "    # We use a B-spline basis function to allow for non-linearity in the mean.\n",
    "    basis_function=BsplineBasisFunction(basis_column=0, nknots=5, degree=3),\n",
    ")\n",
    "sigma1 = make_prior(\n",
    "    # Sigma is also linear, because we want to allow the standard deviation to vary as a function of the covariates: heteroskedasticity.\n",
    "    linear=True,\n",
    "    # The slope coefficients are assumed to be normally distributed, with a mean of 0 and a standard deviation of 2.\n",
    "    slope=make_prior(dist_name=\"Normal\", dist_params=(0.0, 2.0)),\n",
    "    # The intercept is not random, because we assume the intercept of the variance to be the same for all sites and sexes.\n",
    "    intercept=make_prior(dist_name=\"Normal\", dist_params=(1.0, 1.0)),\n",
    "    # We use a B-spline basis function to allow for non-linearity in the standard deviation.\n",
    "    basis_function=BsplineBasisFunction(basis_column=0, nknots=5, degree=3),\n",
    "    # We use a softplus mapping to ensure that sigma is strictly positive.\n",
    "    mapping=\"softplus\",\n",
    "    # We scale the softplus mapping by a factor of 3, to avoid spikes in the resulting density.\n",
    "    # The parameters (a, b, c) provided to a mapping f are used as: f_abc(x) = f((x - a) / b) * b + c\n",
    "    # This basically provides an affine transformation of the softplus function.\n",
    "    # a -> horizontal shift\n",
    "    # b -> scaling\n",
    "    # c -> vertical shift\n",
    "    # You can leave c out, and it will default to 0.\n",
    "    mapping_params=(0.0, 3.0),\n",
    ")\n",
    "# Set the likelihood with the priors we just created.\n",
    "likelihood1 = NormalLikelihood(mu1, sigma1)\n",
    "\n",
    "template_hbr_1 = HBR(\n",
    "    name=\"template\",\n",
    "    # The number of cores to use for sampling.\n",
    "    cores=16,\n",
    "    # Whether to show a progress bar during the model fitting.\n",
    "    progressbar=True,\n",
    "    # The number of draws to sample from the posterior per chain.\n",
    "    draws=1500,\n",
    "    # The number of tuning steps to run.\n",
    "    tune=500,\n",
    "    # The number of MCMC chains to run.\n",
    "    chains=4,\n",
    "    # The sampler to use for the model.\n",
    "    nuts_sampler=\"nutpie\",\n",
    "    # The likelihood function to use for the model.\n",
    "    likelihood=likelihood1,\n",
    ")\n",
    "model1 = NormativeModel(\n",
    "    # The regression model to use for the normative model.\n",
    "    template_regression_model=template_hbr_1,\n",
    "    # Whether to save the model after fitting.\n",
    "    savemodel=True,\n",
    "    # Whether to evaluate the model after fitting.\n",
    "    evaluate_model=True,\n",
    "    # Whether to save the results after evaluation.\n",
    "    saveresults=True,\n",
    "    # Whether to save the plots after fitting.\n",
    "    saveplots=False,\n",
    "    # The directory to save the model, results, and plots.\n",
    "    save_dir=\"resources/compare_hbr/model1\",\n",
    "    # The scaler to use for the input data. Can be either one of \"standardize\", \"minmax\", \"robminmax\", \"none\"\n",
    "    inscaler=\"standardize\",\n",
    "    # The scaler to use for the output data. Can be either one of \"standardize\", \"minmax\", \"robminmax\", \"none\"\n",
    "    outscaler=\"standardize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a4ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2 = make_prior(\n",
    "    # Mu is linear because we want to allow the mean to vary as a function of the covariates.\n",
    "    linear=True,\n",
    "    # The slope coefficients are assumed to be normally distributed, with a mean of 0 and a standard deviation of 10.\n",
    "    slope=make_prior(dist_name=\"Normal\", dist_params=(0.0, 5.0)),\n",
    "    # The intercept is random, because we expect the intercept to vary between sites and sexes.\n",
    "    intercept=make_prior(\n",
    "        random=True,\n",
    "        # Mu is the mean of the intercept, which is normally distributed with a mean of 0 and a standard deviation of 1.\n",
    "        mu=make_prior(dist_name=\"Normal\", dist_params=(0.0, 2.0)),\n",
    "        # Sigma is the scale at which the intercepts vary. It is a positive parameter, so we have to map it to the positive domain.\n",
    "        sigma=make_prior(dist_name=\"Normal\", dist_params=(1.0, 0.5), mapping=\"softplus\", mapping_params=(0.0, 2.0)),\n",
    "    ),\n",
    "    # We use a B-spline basis function to allow for non-linearity in the mean.\n",
    "    basis_function=BsplineBasisFunction(basis_column=0, nknots=5, degree=3),\n",
    ")\n",
    "sigma2 = make_prior(\n",
    "    # Sigma is also linear, because we want to allow the standard deviation to vary as a function of the covariates: heteroskedasticity.\n",
    "    linear=True,\n",
    "    # The slope coefficients are assumed to be normally distributed, with a mean of 0 and a standard deviation of 2.\n",
    "    slope=make_prior(dist_name=\"Normal\", dist_params=(0.0, 2.0)),\n",
    "    # The intercept is not random, because we assume the intercept of the variance to be the same for all sites and sexes.\n",
    "    intercept=make_prior(dist_name=\"Normal\", dist_params=(1.0, 1.0)),\n",
    "    # We use a B-spline basis function to allow for non-linearity in the standard deviation.\n",
    "    basis_function=BsplineBasisFunction(basis_column=0, nknots=5, degree=3),\n",
    "    # We use a softplus mapping to ensure that sigma is strictly positive.\n",
    "    mapping=\"softplus\",\n",
    "    # We scale the softplus mapping by a factor of 3, to avoid spikes in the resulting density.\n",
    "    # The parameters (a, b, c) provided to a mapping f are used as: f_abc(x) = f((x - a) / b) * b + c\n",
    "    # This basically provides an affine transformation of the softplus function.\n",
    "    # a -> horizontal shift\n",
    "    # b -> scaling\n",
    "    # c -> vertical shift\n",
    "    # You can leave c out, and it will default to 0.\n",
    "    mapping_params=(0.0, 3.0),\n",
    ")\n",
    "# Set the likelihood with the priors we just created.\n",
    "likelihood2 = NormalLikelihood(mu2, sigma2)\n",
    "\n",
    "template_hbr_2 = HBR(\n",
    "    name=\"template\",\n",
    "    # The number of cores to use for sampling.\n",
    "    cores=16,\n",
    "    # Whether to show a progress bar during the model fitting.\n",
    "    progressbar=True,\n",
    "    # The number of draws to sample from the posterior per chain.\n",
    "    draws=1500,\n",
    "    # The number of tuning steps to run.\n",
    "    tune=500,\n",
    "    # The number of MCMC chains to run.\n",
    "    chains=4,\n",
    "    # The sampler to use for the model.\n",
    "    nuts_sampler=\"nutpie\",\n",
    "    # The likelihood function to use for the model.\n",
    "    likelihood=likelihood2,\n",
    ")\n",
    "model2 = NormativeModel(\n",
    "    # The regression model to use for the normative model.\n",
    "    template_regression_model=template_hbr_2,\n",
    "    # Whether to save the model after fitting.\n",
    "    savemodel=True,\n",
    "    # Whether to evaluate the model after fitting.\n",
    "    evaluate_model=True,\n",
    "    # Whether to save the results after evaluation.\n",
    "    saveresults=True,\n",
    "    # Whether to save the plots after fitting.\n",
    "    saveplots=False,\n",
    "    # The directory to save the model, results, and plots.\n",
    "    save_dir=\"resources/compare_hbr/model2\",\n",
    "    # The scaler to use for the input data. Can be either one of \"standardize\", \"minmax\", \"robminmax\", \"none\"\n",
    "    inscaler=\"standardize\",\n",
    "    # The scaler to use for the output data. Can be either one of \"standardize\", \"minmax\", \"robminmax\", \"none\"\n",
    "    outscaler=\"standardize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f2cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 83228 - 2025-11-20 13:24:22 - Fitting models on 2 response variables.\n",
      "Process: 83228 - 2025-11-20 13:24:22 - Fitting model for WM-hypointensities.\n"
     ]
    }
   ],
   "source": [
    "model1.fit_predict(train, test)\n",
    "model2.fit_predict(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb28a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete references to model objects to ensure what follows will work for models saved to disk too\n",
    "del model1\n",
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b5b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 83743 - 2025-11-20 13:24:59 - Dataset \"synthesized\" created.\n",
      "    - 92 observations\n",
      "    - 92 unique subjects\n",
      "    - 1 covariates\n",
      "    - 2 response variables\n",
      "    - 2 batch effects:\n",
      "    \tsex (2)\n",
      "\tsite (20)\n",
      "    \n",
      "Process: 83743 - 2025-11-20 13:24:59 - Synthesizing data for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:24:59 - Synthesizing data for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Synthesizing data for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Making predictions on 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Computing z-scores for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Computing z-scores for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Computing z-scores for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Computing centiles for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:00 - Computing centiles for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:01 - Computing centiles for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:01 - Computing log-probabilities for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:01 - Computing log-probabilities for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:02 - Computing log-probabilities for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:02 - Computing yhat for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:02 - Dataset \"synthesized\" created.\n",
      "    - 92 observations\n",
      "    - 92 unique subjects\n",
      "    - 1 covariates\n",
      "    - 2 response variables\n",
      "    - 2 batch effects:\n",
      "    \tsex (2)\n",
      "\tsite (21)\n",
      "    \n",
      "Process: 83743 - 2025-11-20 13:25:02 - Synthesizing data for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:02 - Synthesizing data for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:02 - Synthesizing data for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:03 - Making predictions on 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:03 - Computing z-scores for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:03 - Computing z-scores for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:03 - Computing z-scores for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:03 - Computing centiles for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:03 - Computing centiles for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:05 - Computing centiles for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:06 - Computing log-probabilities for 2 response variables.\n",
      "Process: 83743 - 2025-11-20 13:25:06 - Computing log-probabilities for Right-Lateral-Ventricle.\n",
      "Process: 83743 - 2025-11-20 13:25:06 - Computing log-probabilities for WM-hypointensities.\n",
      "Process: 83743 - 2025-11-20 13:25:07 - Computing yhat for 2 response variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58cd1004f554a819646f931ba3a2fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1c7fb7f8d8461d8011036e13b7f386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b450448c64801a2ace0bbaf0f70bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ptk/lib/python3.12/site-packages/arviz/stats/stats.py:797: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1ba46348a24e1a99e644cad1a8a5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ptk/lib/python3.12/site-packages/arviz/stats/stats.py:797: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ptk/lib/python3.12/site-packages/arviz/stats/stats.py:797: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dct = {\"model1\": \"resources/compare_hbr/model1\", \"model2\": \"resources/compare_hbr/model2\"}\n",
    "comparison = compare_hbr_models(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8865e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-Lateral-Ventricle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>-144.187487</td>\n",
       "      <td>3.818650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.67241</td>\n",
       "      <td>8.123069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>-170.325989</td>\n",
       "      <td>20.296006</td>\n",
       "      <td>26.138503</td>\n",
       "      <td>0.32759</td>\n",
       "      <td>11.779183</td>\n",
       "      <td>15.218179</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank    elpd_loo      p_loo  elpd_diff   weight         se        dse  \\\n",
       "model1     0 -144.187487   3.818650   0.000000  0.67241   8.123069   0.000000   \n",
       "model2     1 -170.325989  20.296006  26.138503  0.32759  11.779183  15.218179   \n",
       "\n",
       "        warning scale  \n",
       "model1    False   log  \n",
       "model2     True   log  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WM-hypointensities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0</td>\n",
       "      <td>-146.022852</td>\n",
       "      <td>12.196037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.552229</td>\n",
       "      <td>10.274826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-159.703623</td>\n",
       "      <td>11.732313</td>\n",
       "      <td>13.680771</td>\n",
       "      <td>0.447771</td>\n",
       "      <td>13.408503</td>\n",
       "      <td>17.475941</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank    elpd_loo      p_loo  elpd_diff    weight         se  \\\n",
       "model2     0 -146.022852  12.196037   0.000000  0.552229  10.274826   \n",
       "model1     1 -159.703623  11.732313  13.680771  0.447771  13.408503   \n",
       "\n",
       "              dse  warning scale  \n",
       "model2   0.000000     True   log  \n",
       "model1  17.475941     True   log  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in comparison.items():\n",
    "    print(k)\n",
    "    display(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
