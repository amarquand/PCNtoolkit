{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel normative modelling\n",
    "\n",
    "This notebook will go through the options of the runner class. We will show how to fit and evaluate a model in parallel, and how to do cross-validation. \n",
    "\n",
    "This notebook is just an adaptation of the 'normative_modelling.ipynb' notebook, so it is recommended that you look at that one first.\n",
    "\n",
    "The notebook is tailored to the Slurm environment on the Donders HPC cluster, but can be adapted to other Slurm or Torque environments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment on the cluster\n",
    "\n",
    "First, SSH into the cluster. If you are using VScode, you can use the Remote - SSH extension to connect to the cluster. It's a breeze. \n",
    "\n",
    "We start with a clean environment and install the PCNtoolkit package. We do this in an interactive job, because it is much faster than using a login node.\n",
    "\n",
    "```bash\n",
    "sbash --time=10:00:00 --mem=16gb -c 4 --ntasks-per-node=1\n",
    "module load anaconda3\n",
    "conda create -n pcntoolkit_cluster_tutorial python=3.12\n",
    "source activate pcntoolkit_cluster_tutorial\n",
    "pip install pcntoolkit\n",
    "pip install ipykernel\n",
    "pip install graphviz\n",
    "```\n",
    "\n",
    "Next, we want to use the newly created environment in our notebook. \n",
    "\n",
    "If you are running this notebook in VScode, you can select the environment by clicking on the mysterious symbol in the top right corner of the notebook. \n",
    "\n",
    "Click \"Select Another Kernel...\", \"Python environments...\", and then from the dropdown, select the `pcntoolkit_cluster_tutorial` environment. \n",
    "\n",
    "You may have to reload the window after creating the environment before it is available in VScode -> Open the command palette (mac: cmd+shift+P, windows: ctrl+shift+P) and type \"Reload Window\"\n",
    "\n",
    "After selecting the environment, the weird symbol in the top right corner should now show the environment name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be the conda environment path: /project/3022000.05/projects/stijdboe/envs/pcntoolkit_cluster_tutorial\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from pcntoolkit.dataio.norm_data import NormData\n",
    "from pcntoolkit.normative_model import NormativeModel\n",
    "from pcntoolkit.regression_model.blr import BLR\n",
    "from pcntoolkit.math.basis_function import BsplineBasisFunction\n",
    "from pcntoolkit.util.runner import Runner\n",
    "import numpy as np\n",
    "import pcntoolkit.util.output\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the conda environment path\n",
    "conda_env_path = os.path.join(os.path.dirname(os.path.dirname(sys.executable)))\n",
    "print(f\"This should be the conda environment path: {conda_env_path}\")\n",
    "\n",
    "# Suppress some annoying warnings and logs\n",
    "pymc_logger = logging.getLogger(\"pymc\")\n",
    "pymc_logger.setLevel(logging.WARNING)\n",
    "pymc_logger.propagate = False\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pcntoolkit.util.output.Output.set_show_messages(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download a small example dataset from github. Saving this dataset on your local device (under 'resources/data/fcon1000.csv' for example) saves time and bandwidth if you re-run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/3022000.05/projects/stijdboe/Projects/PCNtoolkit/examples/resources/data/fcon1000.csv\n",
      "We model 4 variables\n"
     ]
    }
   ],
   "source": [
    "resource_dir = \"resources\"\n",
    "os.makedirs(os.path.join(resource_dir, \"data\"), exist_ok=True)\n",
    "if not os.path.exists(\"resources/data/fcon1000.csv\"):\n",
    "    pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/predictive-clinical-neuroscience/PCNtoolkit-demo/refs/heads/main/data/fcon1000.csv\"\n",
    "    ).to_csv(\"resources/data/fcon1000.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv(\"resources/data/fcon1000.csv\")\n",
    "data[\"sex\"] = np.where(data[\"sex\"], \"Male\", \"Female\")\n",
    "print(os.path.abspath(\"resources/data/fcon1000.csv\"))\n",
    "covariates = [\"age\"]\n",
    "batch_effects = [\"sex\", \"site\"]\n",
    "response_vars = data.columns[3:220]\n",
    "response_vars = data.columns[3:7]\n",
    "print(f\"We model {len(response_vars)} variables\")\n",
    "norm_data = NormData.from_dataframe(\n",
    "    name=\"full\",\n",
    "    dataframe=data,\n",
    "    covariates=[\"age\"],\n",
    "    batch_effects=[\"sex\", \"site\"],\n",
    "    response_vars=response_vars,\n",
    ")\n",
    "transfer_sites = [\"Milwaukee_b\", \"Oulu\"]\n",
    "transfer_data, fit_data = norm_data.split_batch_effects({\"site\": transfer_sites}, names=(\"transfer\", \"fit\"))\n",
    "train, test = fit_data.train_test_split()\n",
    "transfer_train, transfer_test = transfer_data.train_test_split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# BLR model\n",
    "blr_regression_model = BLR(\n",
    "    name=\"template\",\n",
    "    n_iter=1000,\n",
    "    tol=1e-8,\n",
    "    optimizer=\"l-bfgs-b\",\n",
    "    l_bfgs_b_epsilon=0.1,\n",
    "    l_bfgs_b_l=0.1,\n",
    "    l_bfgs_b_norm=\"l2\",\n",
    "    fixed_effect=True,\n",
    "    basis_function_mean=BsplineBasisFunction(basis_column=0, degree=3, nknots=5),\n",
    "    heteroskedastic=True,\n",
    "    basis_function_var=BsplineBasisFunction(basis_column=0, degree=3, nknots=5),\n",
    "    fixed_effect_var=True,\n",
    "    intercept=True,\n",
    "    intercept_var=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NormativeModel(\n",
    "    template_reg_model=blr_regression_model,\n",
    "    # Whether to save the model after fitting.\n",
    "    savemodel=True,\n",
    "    # Whether to evaluate the model after fitting.\n",
    "    evaluate_model=True,\n",
    "    # Whether to save the results after evaluation.\n",
    "    saveresults=True,\n",
    "    # Whether to save the plots after fitting.\n",
    "    saveplots=True,\n",
    "    # The directory to save the model, results, and plots.\n",
    "    save_dir=\"resources/blr/save_dir\",\n",
    "    # The scaler to use for the input data. Can be either one of \"standardize\", \"minmax\", \"robustminmax\", \"none\"\n",
    "    inscaler=\"standardize\",\n",
    "    # The scaler to use for the output data. Can be either one of \"standardize\", \"minmax\", \"robustminmax\", \"none\"\n",
    "    outscaler=\"standardize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "Normally we would just call 'fit_predict' on the model directly, but because we want to use the runner to do cross-validation in parallel, we need to first create a runner object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(\n",
    "    cross_validate=False,\n",
    "    parallelize=True,\n",
    "    environment=conda_env_path,\n",
    "    job_type=\"slurm\",  # or \"torque\" if you are on a torque cluster\n",
    "    n_jobs=2,\n",
    "    time_limit=\"00:10:00\",\n",
    "    log_dir=\"resources/runner_output/log_dir\",\n",
    "    temp_dir=\"resources/runner_output/temp_dir\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runner object will now fit the model in parallel, and save the results in save directories that it will create for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "              PCNtoolkit Job Status Monitor ®\n",
      "---------------------------------------------------------\n",
      "Task uuid: fab69b7e-5623-4d49-aa86-c7daf791b2c4\n",
      "---------------------------------------------------------\n",
      "Job ID      Name          State      Time      Nodes\n",
      "---------------------------------------------------------\n",
      "\n",
      "46951632    ptk_job_0 COMPLETED                          \n",
      "46951633    ptk_job_1 COMPLETED                          \n",
      "\n",
      "---------------------------------------------------------\n",
      "Total active jobs: 0\n",
      "Total completed jobs: 2\n",
      "Total failed jobs: 0\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "No more running jobs!\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.fit_predict(model, train, test, observe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a fold model\n",
    "We can load a model for a specific fold by calling `load_model` on the runner object. This will return a `NormativeModel`, which we can inspect and use to predict on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.normative_model.NormativeModel at 0x7f9c206d7740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitted_model = runner.load_model(1)\n",
    "display(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extension\n",
    "\n",
    "BLR models can only be extended, not transferred (yet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "              PCNtoolkit Job Status Monitor ®\n",
      "---------------------------------------------------------\n",
      "Task uuid: 22ce4fbe-6901-4ec2-91f1-227300b78066\n",
      "---------------------------------------------------------\n",
      "Job ID      Name          State      Time      Nodes\n",
      "---------------------------------------------------------\n",
      "\n",
      "46951634    ptk_job_0 COMPLETED                          \n",
      "46951635    ptk_job_1 COMPLETED                          \n",
      "\n",
      "---------------------------------------------------------\n",
      "Total active jobs: 0\n",
      "Total completed jobs: 2\n",
      "Total failed jobs: 0\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "No more running jobs!\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resources/blr/save_dir_extend/model/normative_model.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/3022000.05/projects/stijdboe/envs/pcntoolkit_cluster_tutorial/lib/python3.12/site-packages/pcntoolkit/util/runner.py:400\u001b[0m, in \u001b[0;36mRunner.extend_predict\u001b[0;34m(self, model, fit_data, predict_data, save_dir, observe)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_observer\u001b[38;5;241m.\u001b[39mwait_for_jobs()\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_jobs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinished_jobs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailed_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_jobs_status()\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m/project/3022000.05/projects/stijdboe/envs/pcntoolkit_cluster_tutorial/lib/python3.12/site-packages/pcntoolkit/util/runner.py:756\u001b[0m, in \u001b[0;36mRunner.load_model\u001b[0;34m(self, fold_index, into)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NormativeModel\u001b[38;5;241m.\u001b[39mload(path, into\u001b[38;5;241m=\u001b[39minto)\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNormativeModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/project/3022000.05/projects/stijdboe/envs/pcntoolkit_cluster_tutorial/lib/python3.12/site-packages/pcntoolkit/normative_model.py:751\u001b[0m, in \u001b[0;36mNormativeModel.load\u001b[0;34m(cls, path, into)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03mLoad a normative model from a path.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;124;03m    This is useful if you want to load a normative model into an existing normative model, for example in the runner.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormative_model.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 751\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    752\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    754\u001b[0m savemodel \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavemodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/blr/save_dir_extend/model/normative_model.json'"
     ]
    }
   ],
   "source": [
    "runner.extend_predict(model, transfer_train, transfer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets with a zscores DataArray will have the `.plot_qq()` function available:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfering and extending with the runner\n",
    "The following functions are available:\n",
    "- `transfer(transfer_data)`: Transfer the model to transfer_data.\n",
    "- `extend(extend_data)`: Extend the model to extend_data.\n",
    "- `transfer_predict(transfer_data, transfer_test)`: Transfer to transfer_test and predict on transfer_test.\n",
    "- `extend_predict(extend_data, extend_test)`: Extend to extend_test and predict on extend_test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
