{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel normative modelling\n",
    "\n",
    "This notebook will go through the options of the runner class. We will show how to fit and evaluate a model in parallel, and how to do cross-validation. \n",
    "\n",
    "This notebook is just an adaptation of the 'normative_modelling.ipynb' notebook, so it is recommended that you look at that one first.\n",
    "\n",
    "The notebook is tailored to the Slurm environment on the Donders HPC cluster, but can be adapted to other Slurm or Torque environments. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment on the cluster\n",
    "\n",
    "First, SSH into the cluster. If you are using VScode, you can use the Remote - SSH extension to connect to the cluster. It's a breeze. \n",
    "\n",
    "We start with a clean environment and install the PCNtoolkit package. We do this in an interactive job, because it is much faster than using a login node.\n",
    "\n",
    "```bash\n",
    "sbash --time=10:00:00 --mem=16gb -c 4 --ntasks-per-node=1\n",
    "module load anaconda3\n",
    "conda create -n pcntoolkit_cluster_tutorial python=3.12\n",
    "source activate pcntoolkit_cluster_tutorial\n",
    "pip install pcntoolkit\n",
    "pip install ipykernel\n",
    "pip install graphviz\n",
    "```\n",
    "\n",
    "Next, we want to use the newly created environment in our notebook. \n",
    "\n",
    "If you are running this notebook in VScode, you can select the environment by clicking on the mysterious symbol in the top right corner of the notebook. \n",
    "\n",
    "Click \"Select Another Kernel...\", \"Python environments...\", and then from the dropdown, select the `pcntoolkit_cluster_tutorial` environment. \n",
    "\n",
    "You may have to reload the window after creating the environment before it is available in VScode -> Open the command palette (mac: cmd+shift+P, windows: ctrl+shift+P) and type \"Reload Window\"\n",
    "\n",
    "After selecting the environment, the weird symbol in the top right corner should now show the environment name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be the conda environment path: /project/3022000.05/projects/stijdboe/envs/pcntoolkit_cluster_tutorial\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from pcntoolkit.dataio.norm_data import NormData\n",
    "from pcntoolkit.normative_model import NormativeModel\n",
    "from pcntoolkit.regression_model.blr import BLR\n",
    "from pcntoolkit.math.basis_function import BsplineBasisFunction\n",
    "from pcntoolkit.util.runner import Runner\n",
    "import numpy as np\n",
    "import pcntoolkit.util.output\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the conda environment path\n",
    "conda_env_path = os.path.join(os.path.dirname(os.path.dirname(sys.executable)))\n",
    "print(f\"This should be the conda environment path: {conda_env_path}\")\n",
    "\n",
    "# Suppress some annoying warnings and logs\n",
    "pymc_logger = logging.getLogger(\"pymc\")\n",
    "pymc_logger.setLevel(logging.WARNING)\n",
    "pymc_logger.propagate = False\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pcntoolkit.util.output.Output.set_show_messages(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download a small example dataset from github. Saving this dataset on your local device (under 'resources/data/fcon1000.csv' for example) saves time and bandwidth if you re-run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/project/3022000.05/projects/stijdboe/Projects/PCNtoolkit/examples/resources/data/fcon1000.csv\n",
      "We model 4 variables\n"
     ]
    }
   ],
   "source": [
    "resource_dir = \"resources\"\n",
    "os.makedirs(os.path.join(resource_dir, \"data\"), exist_ok=True)\n",
    "if not os.path.exists(\"resources/data/fcon1000.csv\"):\n",
    "    pd.read_csv(\n",
    "        \"https://raw.githubusercontent.com/predictive-clinical-neuroscience/PCNtoolkit-demo/refs/heads/main/data/fcon1000.csv\"\n",
    "    ).to_csv(\"resources/data/fcon1000.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv(\"resources/data/fcon1000.csv\")\n",
    "data[\"sex\"] = np.where(data[\"sex\"], \"Male\", \"Female\")\n",
    "print(os.path.abspath(\"resources/data/fcon1000.csv\"))\n",
    "covariates = [\"age\"]\n",
    "batch_effects = [\"sex\", \"site\"]\n",
    "response_vars = data.columns[3:220]\n",
    "response_vars = data.columns[3:7]\n",
    "print(f\"We model {len(response_vars)} variables\")\n",
    "norm_data = NormData.from_dataframe(\n",
    "    name=\"full\",\n",
    "    dataframe=data,\n",
    "    covariates=[\"age\"],\n",
    "    batch_effects=[\"sex\", \"site\"],\n",
    "    response_vars=response_vars,\n",
    ")\n",
    "transfer_sites = [\"Milwaukee_b\", \"Oulu\"]\n",
    "transfer_data, fit_data = norm_data.split_batch_effects({\"site\": transfer_sites}, names=(\"transfer\", \"fit\"))\n",
    "train, test = fit_data.train_test_split()\n",
    "transfer_train, transfer_test = transfer_data.train_test_split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# BLR model\n",
    "blr_regression_model = BLR(\n",
    "    name=\"template\",\n",
    "    n_iter=1000,\n",
    "    tol=1e-8,\n",
    "    optimizer=\"l-bfgs-b\",\n",
    "    l_bfgs_b_epsilon=0.1,\n",
    "    l_bfgs_b_l=0.1,\n",
    "    l_bfgs_b_norm=\"l2\",\n",
    "    fixed_effect=True,\n",
    "    basis_function_mean=BsplineBasisFunction(basis_column=0, degree=3, nknots=5),\n",
    "    heteroskedastic=True,\n",
    "    basis_function_var=BsplineBasisFunction(basis_column=0, degree=3, nknots=5),\n",
    "    fixed_effect_var=True,\n",
    "    intercept=True,\n",
    "    intercept_var=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NormativeModel(\n",
    "    template_reg_model=blr_regression_model,\n",
    "    # Whether to save the model after fitting.\n",
    "    savemodel=True,\n",
    "    # Whether to evaluate the model after fitting.\n",
    "    evaluate_model=True,\n",
    "    # Whether to save the results after evaluation.\n",
    "    saveresults=True,\n",
    "    # Whether to save the plots after fitting.\n",
    "    saveplots=True,\n",
    "    # The directory to save the model, results, and plots.\n",
    "    save_dir=\"resources/blr/save_dir\",\n",
    "    # The scaler to use for the input data. Can be either one of \"standardize\", \"minmax\", \"robustminmax\", \"none\"\n",
    "    inscaler=\"standardize\",\n",
    "    # The scaler to use for the output data. Can be either one of \"standardize\", \"minmax\", \"robustminmax\", \"none\"\n",
    "    outscaler=\"standardize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "Normally we would just call 'fit_predict' on the model directly, but because we want to use the runner to do cross-validation in parallel, we need to first create a runner object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(\n",
    "    cross_validate=False,\n",
    "    parallelize=True,\n",
    "    environment=conda_env_path,\n",
    "    job_type=\"slurm\",  # or \"torque\" if you are on a torque cluster\n",
    "    n_jobs=2,\n",
    "    time_limit=\"00:10:00\",\n",
    "    log_dir=\"resources/runner_output/log_dir\",\n",
    "    temp_dir=\"resources/runner_output/temp_dir\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runner object will now fit the model in parallel, and save the results in save directories that it will create for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "              PCNtoolkit Job Status Monitor ®\n",
      "---------------------------------------------------------\n",
      "Task uuid: e3547c6c-312b-44b4-adeb-841456357e37\n",
      "---------------------------------------------------------\n",
      "Job ID      Name          State      Time      Nodes\n",
      "---------------------------------------------------------\n",
      "\n",
      "46951638    ptk_job_0 COMPLETED                          \n",
      "46951639    ptk_job_1 COMPLETED                          \n",
      "\n",
      "---------------------------------------------------------\n",
      "Total active jobs: 0\n",
      "Total completed jobs: 2\n",
      "Total failed jobs: 0\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "No more running jobs!\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.fit_predict(model, train, test, observe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a fold model\n",
    "We can load a model for a specific fold by calling `load_model` on the runner object. This will return a `NormativeModel`, which we can inspect and use to predict on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.normative_model.NormativeModel at 0x7f3e2b3cd4c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitted_model = runner.load_model(1)\n",
    "display(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model extension\n",
    "\n",
    "BLR models can only be extended, not transferred (yet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------\n",
      "              PCNtoolkit Job Status Monitor ®\n",
      "---------------------------------------------------------\n",
      "Task uuid: 889e4103-b842-4338-8589-292b83d282c8\n",
      "---------------------------------------------------------\n",
      "Job ID      Name          State      Time      Nodes\n",
      "---------------------------------------------------------\n",
      "\n",
      "46951640    ptk_job_0 COMPLETED                          \n",
      "46951641    ptk_job_1 COMPLETED                          \n",
      "\n",
      "---------------------------------------------------------\n",
      "Total active jobs: 0\n",
      "Total completed jobs: 2\n",
      "Total failed jobs: 0\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "No more running jobs!\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pcntoolkit.normative_model.NormativeModel at 0x7f3e2cdcdcd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.extend_predict(model, transfer_train, transfer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets with a zscores DataArray will have the `.plot_qq()` function available:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More to do with the runner\n",
    "\n",
    "The following functions are available:\n",
    "- `transfer(transfer_data)`: Transfer the model to transfer_data.\n",
    "- `extend(extend_data)`: Extend the model to extend_data.\n",
    "- `transfer_predict(transfer_data, transfer_test)`: Transfer to transfer_test and predict on transfer_test.\n",
    "- `extend_predict(extend_data, extend_test)`: Extend to extend_test and predict on extend_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
