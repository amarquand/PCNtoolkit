{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "N_samples = 10000\n",
    "N_features = 2\n",
    "N_covariates = 2\n",
    "X = np.random.randn(N_samples, N_covariates)\n",
    "Y = np.random.randn(N_samples, N_features)\n",
    "sites = np.random.choice(a=3, size=N_samples, replace=True) + 1\n",
    "sex = np.random.choice(a=2, size=N_samples, replace=True) + 1\n",
    "batch_effects = np.stack([sites, sex], axis=1)\n",
    "\n",
    "# Split data into original and transfer\n",
    "original_data_mask = batch_effects[:, 0] != 3\n",
    "X_or = X[original_data_mask]\n",
    "Y_or = Y[original_data_mask]\n",
    "be_or = batch_effects[original_data_mask]\n",
    "\n",
    "transfer_data_mask = batch_effects[:, 0] == 3\n",
    "X_tr = X[transfer_data_mask]\n",
    "Y_tr = Y[transfer_data_mask]\n",
    "be_tr = batch_effects[transfer_data_mask]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_tr_or, X_ts_or, Y_tr_or, Y_ts_or, be_tr_or, be_ts_or = (\n",
    "    sklearn.model_selection.train_test_split(\n",
    "        X_or, Y_or, be_or, test_size=0.2, random_state=1, stratify=be_or[:, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "X_tr_tr, X_ts_tr, Y_tr_tr, Y_ts_tr, be_tr_tr, be_ts_tr = (\n",
    "    sklearn.model_selection.train_test_split(\n",
    "        X_tr, Y_tr, be_tr, test_size=0.2, random_state=1, stratify=be_tr[:, 1]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to file\n",
    "tempdir = \"/Users/stijndeboer/temp\"\n",
    "os.makedirs(tempdir, exist_ok=True)\n",
    "\n",
    "# Original data\n",
    "with open(os.path.join(tempdir, \"X_tr_or.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(X_tr_or), f)\n",
    "with open(os.path.join(tempdir, \"Y_tr_or.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(Y_tr_or), f)\n",
    "with open(os.path.join(tempdir, \"be_tr_or.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(be_tr_or), f)\n",
    "with open(os.path.join(tempdir, \"X_ts_or.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(X_ts_or), f)\n",
    "with open(os.path.join(tempdir, \"Y_ts_or.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(Y_ts_or), f)\n",
    "with open(os.path.join(tempdir, \"be_ts_or.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(be_ts_or), f)\n",
    "\n",
    "# Transfer data\n",
    "with open(os.path.join(tempdir, \"X_tr_tr.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(X_tr_tr), f)\n",
    "with open(os.path.join(tempdir, \"Y_tr_tr.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(Y_tr_tr), f)\n",
    "with open(os.path.join(tempdir, \"be_tr_tr.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(be_tr_tr), f)\n",
    "with open(os.path.join(tempdir, \"X_ts_tr.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(X_ts_tr), f)\n",
    "with open(os.path.join(tempdir, \"Y_ts_tr.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(Y_ts_tr), f)\n",
    "with open(os.path.join(tempdir, \"be_ts_tr.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(pd.DataFrame(be_ts_tr), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inscaler: minmax\n",
      "outscaler: minmax\n",
      "Processing data in /Users/stijndeboer/temp/Y_tr_or.pkl\n",
      "Estimating model  1 of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [mu_slope_mu, sigma_slope_mu, offset_slope_mu, mu_intercept_mu, sigma_intercept_mu, offset_intercept_mu, mu_sigma, sigma_sigma, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e61bcd61974931a722973bc2bd61f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 500 tune and 1_000 draw iterations (500 + 1_000 draws total) took 71 seconds.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Sampling: [y_like]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a1fcd829cc412d841e63bff1bb6ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [y_like]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817267c072b24956b021bb0fef434c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating model  2 of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [mu_slope_mu, sigma_slope_mu, offset_slope_mu, mu_intercept_mu, sigma_intercept_mu, offset_intercept_mu, mu_sigma, sigma_sigma, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e361a884ee44e19b2603a03518465a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 500 tune and 1_000 draw iterations (500 + 1_000 draws total) took 31 seconds.\n",
      "There were 198 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Sampling: [y_like]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3662deb7fb7f4dd997c7ad292912d48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [y_like]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03f25a0843e47e78ecfbe4cee043532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model meta-data...\n",
      "Evaluating the model ...\n",
      "Writing outputs ...\n"
     ]
    }
   ],
   "source": [
    "import pcntoolkit as ptk\n",
    "\n",
    "scaler = \"minmax\"\n",
    "\n",
    "ptk.normative.estimate(\n",
    "    covfile=os.path.join(tempdir, \"X_tr_or.pkl\"),\n",
    "    respfile=os.path.join(tempdir, \"Y_tr_or.pkl\"),\n",
    "    trbefile=os.path.join(tempdir, \"be_tr_or.pkl\"),\n",
    "    testcov=os.path.join(tempdir, \"X_ts_or.pkl\"),\n",
    "    testresp=os.path.join(tempdir, \"Y_ts_or.pkl\"),\n",
    "    tsbefile=os.path.join(tempdir, \"be_ts_or.pkl\"),\n",
    "    inscaler=scaler,\n",
    "    outscaler=scaler,\n",
    "    savemodel=True,\n",
    "    alg=\"hbr\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Using HBR transform...\n",
      "Transferring model  1 of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [mu_slope_mu, sigma_slope_mu, offset_slope_mu, mu_intercept_mu, sigma_intercept_mu, offset_intercept_mu, mu_sigma, sigma_sigma, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c691637af3417a802a9ba95304531a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 500 tune and 1_000 draw iterations (500 + 1_000 draws total) took 14 seconds.\n",
      "There were 16 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Sampling: [y_like]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559a780955244ad8ba0e97a5a833f15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HBR transform...\n",
      "Transferring model  2 of 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [mu_slope_mu, sigma_slope_mu, offset_slope_mu, mu_intercept_mu, sigma_intercept_mu, offset_intercept_mu, mu_sigma, sigma_sigma, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd65ba51e63f4874aa5dc9e21e0a16cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 1 chain for 500 tune and 1_000 draw iterations (500 + 1_000 draws total) took 12 seconds.\n",
      "There were 10 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Sampling: [y_like]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdf1870a2d8401592c9c8758ef1bc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model ...\n",
      "Writing outputs ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.02886982, -0.03568566],\n",
       "        [-0.03630813,  0.0236544 ],\n",
       "        [ 0.06204489, -0.00776436],\n",
       "        ...,\n",
       "        [ 0.07300818, -0.02742723],\n",
       "        [-0.05786122, -0.07673008],\n",
       "        [-0.04668915, -0.01009208]]),\n",
       " array([[1.04617948, 0.92042474],\n",
       "        [0.98979401, 0.92901113],\n",
       "        [1.07487888, 0.97092527],\n",
       "        ...,\n",
       "        [1.00533863, 1.01534088],\n",
       "        [0.99352799, 1.04575208],\n",
       "        [1.02937279, 1.00084325]]),\n",
       " array([[ 1.29090397e+00, -2.48072835e-01],\n",
       "        [-1.25139043e+00, -5.92822900e-01],\n",
       "        [-1.10995884e-01, -1.29110422e-01],\n",
       "        ...,\n",
       "        [-1.59678931e+00, -1.18325424e-04],\n",
       "        [-7.92115492e-01,  1.04373453e-01],\n",
       "        [-2.08458127e+00, -1.49754190e-01]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptk.normative.transfer(\n",
    "    covfile=os.path.join(tempdir, \"X_tr_tr.pkl\"),\n",
    "    respfile=os.path.join(tempdir, \"Y_tr_tr.pkl\"),\n",
    "    trbefile=os.path.join(tempdir, \"be_tr_tr.pkl\"),\n",
    "    testcov=os.path.join(tempdir, \"X_ts_tr.pkl\"),\n",
    "    testresp=os.path.join(tempdir, \"Y_ts_tr.pkl\"),\n",
    "    tsbefile=os.path.join(tempdir, \"be_ts_tr.pkl\"),\n",
    "    alg=\"hbr\",\n",
    "    inscaler=scaler,\n",
    "    outscaler=scaler,\n",
    "    model_path=\"/Users/stijndeboer/Projects/PCN/PCNtoolkit/tests/Models\",\n",
    "    output_path=\"/Users/stijndeboer/Projects/PCN/PCNtoolkit/tests/Models/transfer\",\n",
    "    outputsuffix=\"_transfer\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid_voxels': array([0, 1]), 'fold_num': 1, 'mean_resp': [array([0.01032056, 0.00951302])], 'std_resp': [array([1.01259045, 1.00453476])], 'scaler_cov': [<pcntoolkit.util.utils.scaler object at 0x30be80a10>], 'scaler_resp': [<pcntoolkit.util.utils.scaler object at 0x30bd585c0>], 'regressor': 'hbr', 'inscaler': 'minmax', 'outscaler': 'minmax', 'versions': {'Python': '3.12.0', 'pytensor': '2.26.3', 'PyMC': '5.18.2', 'PCNtoolkit': ''}}\n",
      "{'valid_voxels': array([0, 1]), 'fold_num': 1, 'mean_resp': [array([0.01032056, 0.00951302])], 'std_resp': [array([1.01259045, 1.00453476])], 'scaler_cov': <pcntoolkit.util.utils.scaler object at 0x30432e600>, 'scaler_resp': <pcntoolkit.util.utils.scaler object at 0x30bfb7740>, 'regressor': 'hbr', 'inscaler': 'minmax', 'outscaler': 'minmax', 'versions': {'Python': '3.12.0', 'pytensor': '2.26.3', 'PyMC': '5.18.2', 'PCNtoolkit': ''}}\n"
     ]
    }
   ],
   "source": [
    "# Load the original metadata\n",
    "with open(os.path.join(\"Models\", \"meta_data.md\"), \"rb\") as f:\n",
    "    meta_data = pickle.load(f)\n",
    "\n",
    "print(meta_data)\n",
    "\n",
    "# Load the transfer metadata\n",
    "with open(os.path.join(\"Models\", \"transfer\", \"meta_data.md\"), \"rb\") as f:\n",
    "    meta_data_transfer = pickle.load(f)\n",
    "\n",
    "print(meta_data_transfer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the train data using the original scalers\n",
    "X_tr_or_scaled = meta_data[\"scaler_cov\"][0].transform(X_tr_or)\n",
    "Y_tr_or_scaled = meta_data[\"scaler_resp\"][0].transform(Y_tr_or)\n",
    "\n",
    "# Scale the combined train data using the transfer scalers\n",
    "X_all_scaled = meta_data_transfer[\"scaler_cov\"].transform(\n",
    "    np.concatenate([X_tr_or, X_tr_tr], axis=0)\n",
    ")\n",
    "Y_all_scaled = meta_data_transfer[\"scaler_resp\"].transform(\n",
    "    np.concatenate([Y_tr_or, Y_tr_tr], axis=0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "atol = 1e-3\n",
    "zeros = np.zeros(X_tr_or_scaled.shape[1])\n",
    "ones = np.ones(X_tr_or_scaled.shape[1])\n",
    "if scaler == \"standardize\":\n",
    "    print(np.allclose(X_tr_or_scaled.mean(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(X_tr_or_scaled.std(axis=0), ones, atol=atol))\n",
    "    print(np.allclose(Y_tr_or_scaled.mean(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(Y_tr_or_scaled.std(axis=0), ones, atol=atol))\n",
    "\n",
    "    print(np.allclose(X_all_scaled.mean(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(X_all_scaled.std(axis=0), ones, atol=atol))\n",
    "    print(np.allclose(Y_all_scaled.mean(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(Y_all_scaled.std(axis=0), ones, atol=atol))\n",
    "elif scaler == \"minmax\":\n",
    "    print(np.allclose(X_tr_or_scaled.min(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(X_tr_or_scaled.max(axis=0), ones, atol=atol))\n",
    "    print(np.allclose(Y_tr_or_scaled.min(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(Y_tr_or_scaled.max(axis=0), ones, atol=atol))\n",
    "\n",
    "    print(np.allclose(X_all_scaled.min(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(X_all_scaled.max(axis=0), ones, atol=atol))\n",
    "    print(np.allclose(Y_all_scaled.min(axis=0), zeros, atol=atol))\n",
    "    print(np.allclose(Y_all_scaled.max(axis=0), ones, atol=atol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcntk_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
